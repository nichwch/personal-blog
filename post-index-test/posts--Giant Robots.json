{"The movie Pacific Rim is about giant robots fighting monsters. It is one of many examples of science fiction focused on giant robots, but all of them have something in common: the giant robot is piloted by a human being.": [{"content": "The movie Pacific Rim is about giant robots fighting monsters. It is one of many examples of science fiction focused on giant robots, but all of them have something in common: the giant robot is piloted by a human being.", "parent": "Giant Robots.txt", "score": -1.1920928955078125e-07}, {"content": "If you think about that a bit, it's a very quaint idea. Can you imagine a world where technology has developed to the point where we have giant robots, but technology is not somehow advanced enough to autopilot them? The idea seems strange to us, because in many respects, we live in a world diametrically opposed to the one portrayed in mecha science fiction. In their world, human beings control towering 50-foot humanoid war mechs. In ours, we are ruled by 5 inch screens in our pockets.", "parent": "Giant Robots.txt", "score": 0.41926079988479614}, {"content": "A point worth repeating: in mecha fiction, we control 50-foot-tall war robots, in our world, we are controlled by the 5 inch screens in our pocket.", "parent": "Giant Robots.txt", "score": 0.49473094940185547}, {"content": "The underlying psychological desire that mecha fiction appeals to is this: a world where technology augments the individual instead of replacing/controlling the individual. It is important that the mechs in these stories are humanoid, and not tanks or some other kind of war machine - in these worlds, we command machines that we created in our own image.", "parent": "Giant Robots.txt", "score": 0.5321229100227356}, {"content": "The problem with the view that technology is meant to solve problems is that technology always ends up doing so much more than that. Take any technology and its original intended purpose (fire, automobiles, airplanes, etc.) and you will find it has created a cascade of second order effects far beyond what it was originally intended to do. Sometimes these impacts are good, sometimes they're bad, sometimes they're just strange. ", "parent": "Creating new kinds of people.txt", "score": 0.7319743037223816}, {"content": "If the internet is a hurricane of information, let us build steely exoskeletons to weather the storm.", "parent": "Giant Robots.txt", "score": 0.749965488910675}, {"content": "To what degree can you control what you see on your phone? On any major social media site? The overwhelming trend of the last decade has been to replace user-controlled feeds with algorithmically curated ones. When you go to a newspaper stand, you pick which paper you'd like, which section you'd like to browse, and which article you'd like to read. When you open Facebook, what you see is decided for you by an algorithm mathematically optimized to maximize the amount of time you spend in the app. In the first scenario, the experience is like browsing a menu and ordering a meal. Choices are offered, a deliberation is made. In the second scenario, the content is slop, and the user is a pig eating it from a trough.", "parent": "Giant Robots.txt", "score": 0.778590202331543}, {"content": "In my view, the whole movement of [[tools for thought]] (Roam, personal knowledge management systems, etc, etc.) is to make computers help us think better. That was the point from the very start, it was what Steve Jobs meant when he called the computer \"a bicycle for the mind.\" In the last decade, we've seen the very opposite - the use of the computer as an extractive tool, a weapon to siphon attention and harvest data. ", "parent": "Controlling what you see.txt", "score": 0.7799962300121422}, {"content": "Users should have complete control over what they see. I'm not saying algorithmic feeds don't have their place, but they should be something users opt in to. Andy [[Matuschak]] coined the idea of \"[programmable attention](https://notes.andymatuschak.org/zJrfPCbY7GcpV9asEc8NTVzXTAV4TvRFMuY6)\" as something [[tools for thought]] could enable. I will say that this already exists, only in the opposite, sinister sense - right now it's the platform programming your attention, not you. ", "parent": "Controlling what you see.txt", "score": 0.7901822480992018}, {"content": "The usual way to think about technology, software, and startups is that they solve problems, and so it follows then that the best way to create a new technology is to find a problem people have and solve it. This is not a bad approach to take, and it's been successful for many people. Still, I think it's too narrow.", "parent": "Creating new kinds of people.txt", "score": 0.7908668518066406}], "": [{"content": "~", "parent": "Fragments.txt", "score": 0.6013129949569702}, {"content": "~", "parent": "Fragments.txt", "score": 0.6013447046279907}, {"content": "~", "parent": "Fragments.txt", "score": 0.6013447046279907}, {"content": "~", "parent": "Fragments.txt", "score": 0.6013447046279907}, {"content": "~", "parent": "Fragments.txt", "score": 0.6013447046279907}, {"content": "~", "parent": "Fragments.txt", "score": 0.6013447046279907}, {"content": "Code:", "parent": "Goals for Spring Quarter.txt", "score": 0.6476607090126701}, {"content": "Executing", "parent": "Goals for Spring Quarter.txt", "score": 0.700144949274238}, {"content": "Hobbies:", "parent": "Goals for Spring Quarter.txt", "score": 0.7317217515199471}, {"content": "Priority 1: Code-related creative work (continue work on exegesis, other personal projects, learn more code, write more)", "parent": "Goals for Spring Quarter.txt", "score": 0.7384507224011272}], "If you think about that a bit, it's a very quaint idea. Can you imagine a world where technology has developed to the point where we have giant robots, but technology is not somehow advanced enough to autopilot them? The idea seems strange to us, because in many respects, we live in a world diametrically opposed to the one portrayed in mecha science fiction. In their world, human beings control towering 50-foot humanoid war mechs. In ours, we are ruled by 5 inch screens in our pockets.": [{"content": "If you think about that a bit, it's a very quaint idea. Can you imagine a world where technology has developed to the point where we have giant robots, but technology is not somehow advanced enough to autopilot them? The idea seems strange to us, because in many respects, we live in a world diametrically opposed to the one portrayed in mecha science fiction. In their world, human beings control towering 50-foot humanoid war mechs. In ours, we are ruled by 5 inch screens in our pockets.", "parent": "Giant Robots.txt", "score": 5.960464477539062e-07}, {"content": "A point worth repeating: in mecha fiction, we control 50-foot-tall war robots, in our world, we are controlled by the 5 inch screens in our pocket.", "parent": "Giant Robots.txt", "score": 0.24003803730010986}, {"content": "The underlying psychological desire that mecha fiction appeals to is this: a world where technology augments the individual instead of replacing/controlling the individual. It is important that the mechs in these stories are humanoid, and not tanks or some other kind of war machine - in these worlds, we command machines that we created in our own image.", "parent": "Giant Robots.txt", "score": 0.29825735092163086}, {"content": "The movie Pacific Rim is about giant robots fighting monsters. It is one of many examples of science fiction focused on giant robots, but all of them have something in common: the giant robot is piloted by a human being.", "parent": "Giant Robots.txt", "score": 0.4192904233932495}, {"content": "The problem with the view that technology is meant to solve problems is that technology always ends up doing so much more than that. Take any technology and its original intended purpose (fire, automobiles, airplanes, etc.) and you will find it has created a cascade of second order effects far beyond what it was originally intended to do. Sometimes these impacts are good, sometimes they're bad, sometimes they're just strange. ", "parent": "Creating new kinds of people.txt", "score": 0.5561336278915405}, {"content": "Users should have complete control over what they see. I'm not saying algorithmic feeds don't have their place, but they should be something users opt in to. Andy [[Matuschak]] coined the idea of \"[programmable attention](https://notes.andymatuschak.org/zJrfPCbY7GcpV9asEc8NTVzXTAV4TvRFMuY6)\" as something [[tools for thought]] could enable. I will say that this already exists, only in the opposite, sinister sense - right now it's the platform programming your attention, not you. ", "parent": "Controlling what you see.txt", "score": 0.5926140386671526}, {"content": "In my view, the whole movement of [[tools for thought]] (Roam, personal knowledge management systems, etc, etc.) is to make computers help us think better. That was the point from the very start, it was what Steve Jobs meant when he called the computer \"a bicycle for the mind.\" In the last decade, we've seen the very opposite - the use of the computer as an extractive tool, a weapon to siphon attention and harvest data. ", "parent": "Controlling what you see.txt", "score": 0.5965980803547505}, {"content": "My dream is to enable something I term \"generational computing.\" I want my kids and my grandkids to someday be able to interface with the artifacts of my digital life. I want them to be able to read my notes and ask an LLM about what I've learned over my life. I want them to be able to chat with a replica of me trained on my writings. I want them to be able to look through the music I made and the music I listened to, and see the connections between the two. I want them to be able to upload their own musical ideas or writings, and see the connections between what they've made and what I've made. ", "parent": "Generational Computing.txt", "score": 0.6138881892964114}, {"content": "To what degree can you control what you see on your phone? On any major social media site? The overwhelming trend of the last decade has been to replace user-controlled feeds with algorithmically curated ones. When you go to a newspaper stand, you pick which paper you'd like, which section you'd like to browse, and which article you'd like to read. When you open Facebook, what you see is decided for you by an algorithm mathematically optimized to maximize the amount of time you spend in the app. In the first scenario, the experience is like browsing a menu and ordering a meal. Choices are offered, a deliberation is made. In the second scenario, the content is slop, and the user is a pig eating it from a trough.", "parent": "Giant Robots.txt", "score": 0.6200031042098999}, {"content": "The usual way to think about technology, software, and startups is that they solve problems, and so it follows then that the best way to create a new technology is to find a problem people have and solve it. This is not a bad approach to take, and it's been successful for many people. Still, I think it's too narrow.", "parent": "Creating new kinds of people.txt", "score": 0.6472820043563843}], "The underlying psychological desire that mecha fiction appeals to is this: a world where technology augments the individual instead of replacing/controlling the individual. It is important that the mechs in these stories are humanoid, and not tanks or some other kind of war machine - in these worlds, we command machines that we created in our own image.": [{"content": "The underlying psychological desire that mecha fiction appeals to is this: a world where technology augments the individual instead of replacing/controlling the individual. It is important that the mechs in these stories are humanoid, and not tanks or some other kind of war machine - in these worlds, we command machines that we created in our own image.", "parent": "Giant Robots.txt", "score": 5.960464477539063e-08}, {"content": "If you think about that a bit, it's a very quaint idea. Can you imagine a world where technology has developed to the point where we have giant robots, but technology is not somehow advanced enough to autopilot them? The idea seems strange to us, because in many respects, we live in a world diametrically opposed to the one portrayed in mecha science fiction. In their world, human beings control towering 50-foot humanoid war mechs. In ours, we are ruled by 5 inch screens in our pockets.", "parent": "Giant Robots.txt", "score": 0.2982279062271118}, {"content": "A point worth repeating: in mecha fiction, we control 50-foot-tall war robots, in our world, we are controlled by the 5 inch screens in our pocket.", "parent": "Giant Robots.txt", "score": 0.32440340518951416}, {"content": "The movie Pacific Rim is about giant robots fighting monsters. It is one of many examples of science fiction focused on giant robots, but all of them have something in common: the giant robot is piloted by a human being.", "parent": "Giant Robots.txt", "score": 0.5321229100227356}, {"content": "Users should have complete control over what they see. I'm not saying algorithmic feeds don't have their place, but they should be something users opt in to. Andy [[Matuschak]] coined the idea of \"[programmable attention](https://notes.andymatuschak.org/zJrfPCbY7GcpV9asEc8NTVzXTAV4TvRFMuY6)\" as something [[tools for thought]] could enable. I will say that this already exists, only in the opposite, sinister sense - right now it's the platform programming your attention, not you. ", "parent": "Controlling what you see.txt", "score": 0.6259182754820187}, {"content": "The problem with the view that technology is meant to solve problems is that technology always ends up doing so much more than that. Take any technology and its original intended purpose (fire, automobiles, airplanes, etc.) and you will find it has created a cascade of second order effects far beyond what it was originally intended to do. Sometimes these impacts are good, sometimes they're bad, sometimes they're just strange. ", "parent": "Creating new kinds of people.txt", "score": 0.6493030786514282}, {"content": "My dream is to enable something I term \"generational computing.\" I want my kids and my grandkids to someday be able to interface with the artifacts of my digital life. I want them to be able to read my notes and ask an LLM about what I've learned over my life. I want them to be able to chat with a replica of me trained on my writings. I want them to be able to look through the music I made and the music I listened to, and see the connections between the two. I want them to be able to upload their own musical ideas or writings, and see the connections between what they've made and what I've made. ", "parent": "Generational Computing.txt", "score": 0.6493455392034182}, {"content": "In my view, the whole movement of [[tools for thought]] (Roam, personal knowledge management systems, etc, etc.) is to make computers help us think better. That was the point from the very start, it was what Steve Jobs meant when he called the computer \"a bicycle for the mind.\" In the last decade, we've seen the very opposite - the use of the computer as an extractive tool, a weapon to siphon attention and harvest data. ", "parent": "Controlling what you see.txt", "score": 0.6568129098973268}, {"content": "I want digital technology to bridge divides between generations instead of widening them. I want it to foster remembrance instead of forgetting. I want it to reward thinking multiple generations into the future instead of until the end of the quarter.", "parent": "Generational Computing.txt", "score": 0.6634881846364071}, {"content": "I don't just mean that technologies create new sorts of jobs, which is a true statement but in my opinion understates the significance of what is being done. Each of the examples given above did not merely create a new kind of occupation - they created a nexus of richly interlinked cultural artifacts, characters, and identities. The introduction of the social media influencer did far more than just introduce a new kind of occupation. It also created a new social hierarchy, threatened old social hierarchies (the beef between old Hollywood elites and new internet stars, etc. etc.), [influenced the goals of an entire generation](https://www.fastcompany.com/90432765/why-do-kids-want-to-be-influencers), and resulted in a reordering of values where old values like modesty and moderation gave way to exuberance and excess. The sum of these new hierarchies, values, and occupations is the creation of a new type of person.", "parent": "Creating new kinds of people.txt", "score": 0.6847434043884277}], "// Technology that controls you": [{"content": "Users should have complete control over what they see. I'm not saying algorithmic feeds don't have their place, but they should be something users opt in to. Andy [[Matuschak]] coined the idea of \"[programmable attention](https://notes.andymatuschak.org/zJrfPCbY7GcpV9asEc8NTVzXTAV4TvRFMuY6)\" as something [[tools for thought]] could enable. I will say that this already exists, only in the opposite, sinister sense - right now it's the platform programming your attention, not you. ", "parent": "Controlling what you see.txt", "score": 0.6283280468823855}, {"content": "If you think about that a bit, it's a very quaint idea. Can you imagine a world where technology has developed to the point where we have giant robots, but technology is not somehow advanced enough to autopilot them? The idea seems strange to us, because in many respects, we live in a world diametrically opposed to the one portrayed in mecha science fiction. In their world, human beings control towering 50-foot humanoid war mechs. In ours, we are ruled by 5 inch screens in our pockets.", "parent": "Giant Robots.txt", "score": 0.6392155289649963}, {"content": "A point worth repeating: in mecha fiction, we control 50-foot-tall war robots, in our world, we are controlled by the 5 inch screens in our pocket.", "parent": "Giant Robots.txt", "score": 0.6846634149551392}, {"content": "The problem with the view that technology is meant to solve problems is that technology always ends up doing so much more than that. Take any technology and its original intended purpose (fire, automobiles, airplanes, etc.) and you will find it has created a cascade of second order effects far beyond what it was originally intended to do. Sometimes these impacts are good, sometimes they're bad, sometimes they're just strange. ", "parent": "Creating new kinds of people.txt", "score": 0.699651837348938}, {"content": "The underlying psychological desire that mecha fiction appeals to is this: a world where technology augments the individual instead of replacing/controlling the individual. It is important that the mechs in these stories are humanoid, and not tanks or some other kind of war machine - in these worlds, we command machines that we created in our own image.", "parent": "Giant Robots.txt", "score": 0.6999948024749756}, {"content": "In my view, the whole movement of [[tools for thought]] (Roam, personal knowledge management systems, etc, etc.) is to make computers help us think better. That was the point from the very start, it was what Steve Jobs meant when he called the computer \"a bicycle for the mind.\" In the last decade, we've seen the very opposite - the use of the computer as an extractive tool, a weapon to siphon attention and harvest data. ", "parent": "Controlling what you see.txt", "score": 0.7100881358893585}, {"content": "I desperately want programming to feel like this.", "parent": "Fragments.txt", "score": 0.7168856859207153}, {"content": "To what degree can you control what you see on your phone? On any major social media site? The overwhelming trend of the last decade has been to replace user-controlled feeds with algorithmically curated ones. When you go to a newspaper stand, you pick which paper you'd like, which section you'd like to browse, and which article you'd like to read. When you open Facebook, what you see is decided for you by an algorithm mathematically optimized to maximize the amount of time you spend in the app. In the first scenario, the experience is like browsing a menu and ordering a meal. Choices are offered, a deliberation is made. In the second scenario, the content is slop, and the user is a pig eating it from a trough.", "parent": "Giant Robots.txt", "score": 0.7197145223617554}, {"content": "I'm convinced that algorithmic feeds are poisonous. Algorithmic feeds in apps are like cocaine in old medicines or asbestos in buildings, and someday they'll be seen to be just as barbaric.", "parent": "Controlling what you see.txt", "score": 0.7421276714606374}, {"content": "There is a particular kind of second order effect that is of special interest: technologies can create entire new types of people. Instagram created the influencer, Youtube produced the Youtuber, Soundcloud spawned its own eponymous kind of rapper. The more extreme political factions in America trace their lineages to 4Chan and Tumblr. To give an older example, the factory birthed the proletariat a century ago. ", "parent": "Creating new kinds of people.txt", "score": 0.7431483268737793}], "A point worth repeating: in mecha fiction, we control 50-foot-tall war robots, in our world, we are controlled by the 5 inch screens in our pocket.": [{"content": "A point worth repeating: in mecha fiction, we control 50-foot-tall war robots, in our world, we are controlled by the 5 inch screens in our pocket.", "parent": "Giant Robots.txt", "score": 0.0}, {"content": "If you think about that a bit, it's a very quaint idea. Can you imagine a world where technology has developed to the point where we have giant robots, but technology is not somehow advanced enough to autopilot them? The idea seems strange to us, because in many respects, we live in a world diametrically opposed to the one portrayed in mecha science fiction. In their world, human beings control towering 50-foot humanoid war mechs. In ours, we are ruled by 5 inch screens in our pockets.", "parent": "Giant Robots.txt", "score": 0.23996591567993164}, {"content": "The underlying psychological desire that mecha fiction appeals to is this: a world where technology augments the individual instead of replacing/controlling the individual. It is important that the mechs in these stories are humanoid, and not tanks or some other kind of war machine - in these worlds, we command machines that we created in our own image.", "parent": "Giant Robots.txt", "score": 0.32440340518951416}, {"content": "The movie Pacific Rim is about giant robots fighting monsters. It is one of many examples of science fiction focused on giant robots, but all of them have something in common: the giant robot is piloted by a human being.", "parent": "Giant Robots.txt", "score": 0.49473094940185547}, {"content": "Users should have complete control over what they see. I'm not saying algorithmic feeds don't have their place, but they should be something users opt in to. Andy [[Matuschak]] coined the idea of \"[programmable attention](https://notes.andymatuschak.org/zJrfPCbY7GcpV9asEc8NTVzXTAV4TvRFMuY6)\" as something [[tools for thought]] could enable. I will say that this already exists, only in the opposite, sinister sense - right now it's the platform programming your attention, not you. ", "parent": "Controlling what you see.txt", "score": 0.6417620798457697}, {"content": "If the internet is a hurricane of information, let us build steely exoskeletons to weather the storm.", "parent": "Giant Robots.txt", "score": 0.6670737266540527}, {"content": "To what degree can you control what you see on your phone? On any major social media site? The overwhelming trend of the last decade has been to replace user-controlled feeds with algorithmically curated ones. When you go to a newspaper stand, you pick which paper you'd like, which section you'd like to browse, and which article you'd like to read. When you open Facebook, what you see is decided for you by an algorithm mathematically optimized to maximize the amount of time you spend in the app. In the first scenario, the experience is like browsing a menu and ordering a meal. Choices are offered, a deliberation is made. In the second scenario, the content is slop, and the user is a pig eating it from a trough.", "parent": "Giant Robots.txt", "score": 0.6933445930480957}, {"content": "From pg 28 of Understanding Media by Marshall McLuhan", "parent": "Fragments.txt", "score": 0.6965003609657288}, {"content": "I desperately want programming to feel like this.", "parent": "Fragments.txt", "score": 0.6981407403945923}, {"content": "In my view, the whole movement of [[tools for thought]] (Roam, personal knowledge management systems, etc, etc.) is to make computers help us think better. That was the point from the very start, it was what Steve Jobs meant when he called the computer \"a bicycle for the mind.\" In the last decade, we've seen the very opposite - the use of the computer as an extractive tool, a weapon to siphon attention and harvest data. ", "parent": "Controlling what you see.txt", "score": 0.6999537238843299}], "To what degree can you control what you see on your phone? On any major social media site? The overwhelming trend of the last decade has been to replace user-controlled feeds with algorithmically curated ones. When you go to a newspaper stand, you pick which paper you'd like, which section you'd like to browse, and which article you'd like to read. When you open Facebook, what you see is decided for you by an algorithm mathematically optimized to maximize the amount of time you spend in the app. In the first scenario, the experience is like browsing a menu and ordering a meal. Choices are offered, a deliberation is made. In the second scenario, the content is slop, and the user is a pig eating it from a trough.": [{"content": "To what degree can you control what you see on your phone? On any major social media site? The overwhelming trend of the last decade has been to replace user-controlled feeds with algorithmically curated ones. When you go to a newspaper stand, you pick which paper you'd like, which section you'd like to browse, and which article you'd like to read. When you open Facebook, what you see is decided for you by an algorithm mathematically optimized to maximize the amount of time you spend in the app. In the first scenario, the experience is like browsing a menu and ordering a meal. Choices are offered, a deliberation is made. In the second scenario, the content is slop, and the user is a pig eating it from a trough.", "parent": "Giant Robots.txt", "score": 1.1920928955078125e-07}, {"content": "Users should have complete control over what they see. I'm not saying algorithmic feeds don't have their place, but they should be something users opt in to. Andy [[Matuschak]] coined the idea of \"[programmable attention](https://notes.andymatuschak.org/zJrfPCbY7GcpV9asEc8NTVzXTAV4TvRFMuY6)\" as something [[tools for thought]] could enable. I will say that this already exists, only in the opposite, sinister sense - right now it's the platform programming your attention, not you. ", "parent": "Controlling what you see.txt", "score": 0.3795488401201167}, {"content": "I'm convinced that algorithmic feeds are poisonous. Algorithmic feeds in apps are like cocaine in old medicines or asbestos in buildings, and someday they'll be seen to be just as barbaric.", "parent": "Controlling what you see.txt", "score": 0.4792614251938435}, {"content": "Upset at this state of affairs, I found [a chrome extension](https://chrome.google.com/webstore/detail/news-feed-eradicator/fjcldmjmjhkklehbacihaiopjklihlgg?hl=en) that disabled the \"feeds\" on a number of sites (Facebook, Youtube, LinkedIn, even HackerNews). This helped immediately. The unconscious, muscle-memory impulse to press Y and autocomplete into Youtube was still there, but when I opened the page, the algorithmic suggestions were all gone. Staring at the blank space, I would realize that I hadn't opened Youtube because I really wanted to watch anything, I had opened it because it was my impulse to do that while bored. ", "parent": "Controlling what you see.txt", "score": 0.4865717435110022}, {"content": "Who cares? Make all the metaphysical arguments you'd like, a sufficiently powerful recommendation algorithm will still be able to sway decisions enough for Facebook to make 86 billion dollars a year. Free will may or may not be real, but it is an empirical fact that the profitable choice is to act as if it isn't.", "parent": "Giant Robots.txt", "score": 0.49377214908599854}, {"content": "But the user has chosen to open Facebook, and chosen to sign up for the service. Isn't this a philosophical question about choice? Isn't free will real? ", "parent": "Giant Robots.txt", "score": 0.5382394790649414}, {"content": "I spend an inordinate amount of time on Youtube. Having noticed this one morning, I quietly told myself that I wouldn't check Youtube for the rest of the work session - only to find that I would unconsciously press \"Y+enter\" and let the address bar's autocomplete lead me to Youtube. I would find myself on the site, not remembering how I had gotten there. More importantly, the home page recommendations had learned my preferences incredibly well. As soon as I landed on Youtube, there would be at least one video there ready for me to watch. That morning, I got nothing done. Youtube's algorithm had figured out that I really liked watching short clips of Mad Men and provided me a steady drip-feed of them, which I gorged on instead of getting anything done. ", "parent": "Controlling what you see.txt", "score": 0.5412110090255737}, {"content": "None of the above. I got a targeted Facebook ad for Fender's free online guitar course. I remember this very distinctly as the moment I decided to learn guitar; I had never really thought much about it at all before that. Deep within the entrails of Facebook's recommendation engine, some algorithm made an educated guess that I'd enjoy picking up the guitar - and it was right. For all the horrible things Facebook has done, this was a real positive-sum, Pareto optimal moment. Zuck got his advertising check, and I got a new hobby. And for all that has been blamed on the internet, I owe it everything. Everything that I love doing, I have learned to some extent from the internet, whether it be the web development skills that I built exegesis with, my amateur interest in philosophy, my childhood love for art, or my newfound interest in guitar. I believe it is mankind's most beautiful invention.", "parent": "Giant Robots.txt", "score": 0.5578176975250244}, {"content": "Here's a radical statement: All applications should be tools for thought. Facebook should be a tool for keeping up with friends, Instagram should be a tool for browsing and sharing photographs. [[tools for thought]] [[Manifesto]] ", "parent": "Controlling what you see.txt", "score": 0.5701605492537873}, {"content": "There is a particular kind of second order effect that is of special interest: technologies can create entire new types of people. Instagram created the influencer, Youtube produced the Youtuber, Soundcloud spawned its own eponymous kind of rapper. The more extreme political factions in America trace their lineages to 4Chan and Tumblr. To give an older example, the factory birthed the proletariat a century ago. ", "parent": "Creating new kinds of people.txt", "score": 0.5814118385314941}], "But the user has chosen to open Facebook, and chosen to sign up for the service. Isn't this a philosophical question about choice? Isn't free will real? ": [{"content": "But the user has chosen to open Facebook, and chosen to sign up for the service. Isn't this a philosophical question about choice? Isn't free will real? ", "parent": "Giant Robots.txt", "score": 2.682209014892578e-06}, {"content": "Who cares? Make all the metaphysical arguments you'd like, a sufficiently powerful recommendation algorithm will still be able to sway decisions enough for Facebook to make 86 billion dollars a year. Free will may or may not be real, but it is an empirical fact that the profitable choice is to act as if it isn't.", "parent": "Giant Robots.txt", "score": 0.4193059206008911}, {"content": "To what degree can you control what you see on your phone? On any major social media site? The overwhelming trend of the last decade has been to replace user-controlled feeds with algorithmically curated ones. When you go to a newspaper stand, you pick which paper you'd like, which section you'd like to browse, and which article you'd like to read. When you open Facebook, what you see is decided for you by an algorithm mathematically optimized to maximize the amount of time you spend in the app. In the first scenario, the experience is like browsing a menu and ordering a meal. Choices are offered, a deliberation is made. In the second scenario, the content is slop, and the user is a pig eating it from a trough.", "parent": "Giant Robots.txt", "score": 0.5383428335189819}, {"content": "None of the above. I got a targeted Facebook ad for Fender's free online guitar course. I remember this very distinctly as the moment I decided to learn guitar; I had never really thought much about it at all before that. Deep within the entrails of Facebook's recommendation engine, some algorithm made an educated guess that I'd enjoy picking up the guitar - and it was right. For all the horrible things Facebook has done, this was a real positive-sum, Pareto optimal moment. Zuck got his advertising check, and I got a new hobby. And for all that has been blamed on the internet, I owe it everything. Everything that I love doing, I have learned to some extent from the internet, whether it be the web development skills that I built exegesis with, my amateur interest in philosophy, my childhood love for art, or my newfound interest in guitar. I believe it is mankind's most beautiful invention.", "parent": "Giant Robots.txt", "score": 0.56498122215271}, {"content": "Here's a radical statement: All applications should be tools for thought. Facebook should be a tool for keeping up with friends, Instagram should be a tool for browsing and sharing photographs. [[tools for thought]] [[Manifesto]] ", "parent": "Controlling what you see.txt", "score": 0.5720762666403623}, {"content": "Users should have complete control over what they see. I'm not saying algorithmic feeds don't have their place, but they should be something users opt in to. Andy [[Matuschak]] coined the idea of \"[programmable attention](https://notes.andymatuschak.org/zJrfPCbY7GcpV9asEc8NTVzXTAV4TvRFMuY6)\" as something [[tools for thought]] could enable. I will say that this already exists, only in the opposite, sinister sense - right now it's the platform programming your attention, not you. ", "parent": "Controlling what you see.txt", "score": 0.5923560847659584}, {"content": "Upset at this state of affairs, I found [a chrome extension](https://chrome.google.com/webstore/detail/news-feed-eradicator/fjcldmjmjhkklehbacihaiopjklihlgg?hl=en) that disabled the \"feeds\" on a number of sites (Facebook, Youtube, LinkedIn, even HackerNews). This helped immediately. The unconscious, muscle-memory impulse to press Y and autocomplete into Youtube was still there, but when I opened the page, the algorithmic suggestions were all gone. Staring at the blank space, I would realize that I hadn't opened Youtube because I really wanted to watch anything, I had opened it because it was my impulse to do that while bored. ", "parent": "Controlling what you see.txt", "score": 0.635887274856619}, {"content": "Traditional market research asks the question, what sorts of people would use our product? A useful question, to be sure, but the more interesting one is what new sort of person would our product create? ", "parent": "Creating new kinds of people.txt", "score": 0.681763768196106}, {"content": "In my view, the whole movement of [[tools for thought]] (Roam, personal knowledge management systems, etc, etc.) is to make computers help us think better. That was the point from the very start, it was what Steve Jobs meant when he called the computer \"a bicycle for the mind.\" In the last decade, we've seen the very opposite - the use of the computer as an extractive tool, a weapon to siphon attention and harvest data. ", "parent": "Controlling what you see.txt", "score": 0.7041252868448094}, {"content": "There is a particular kind of second order effect that is of special interest: technologies can create entire new types of people. Instagram created the influencer, Youtube produced the Youtuber, Soundcloud spawned its own eponymous kind of rapper. The more extreme political factions in America trace their lineages to 4Chan and Tumblr. To give an older example, the factory birthed the proletariat a century ago. ", "parent": "Creating new kinds of people.txt", "score": 0.7091042995452881}], "Who cares? Make all the metaphysical arguments you'd like, a sufficiently powerful recommendation algorithm will still be able to sway decisions enough for Facebook to make 86 billion dollars a year. Free will may or may not be real, but it is an empirical fact that the profitable choice is to act as if it isn't.": [{"content": "Who cares? Make all the metaphysical arguments you'd like, a sufficiently powerful recommendation algorithm will still be able to sway decisions enough for Facebook to make 86 billion dollars a year. Free will may or may not be real, but it is an empirical fact that the profitable choice is to act as if it isn't.", "parent": "Giant Robots.txt", "score": -4.76837158203125e-07}, {"content": "But the user has chosen to open Facebook, and chosen to sign up for the service. Isn't this a philosophical question about choice? Isn't free will real? ", "parent": "Giant Robots.txt", "score": 0.4192752242088318}, {"content": "To what degree can you control what you see on your phone? On any major social media site? The overwhelming trend of the last decade has been to replace user-controlled feeds with algorithmically curated ones. When you go to a newspaper stand, you pick which paper you'd like, which section you'd like to browse, and which article you'd like to read. When you open Facebook, what you see is decided for you by an algorithm mathematically optimized to maximize the amount of time you spend in the app. In the first scenario, the experience is like browsing a menu and ordering a meal. Choices are offered, a deliberation is made. In the second scenario, the content is slop, and the user is a pig eating it from a trough.", "parent": "Giant Robots.txt", "score": 0.49377214908599854}, {"content": "None of the above. I got a targeted Facebook ad for Fender's free online guitar course. I remember this very distinctly as the moment I decided to learn guitar; I had never really thought much about it at all before that. Deep within the entrails of Facebook's recommendation engine, some algorithm made an educated guess that I'd enjoy picking up the guitar - and it was right. For all the horrible things Facebook has done, this was a real positive-sum, Pareto optimal moment. Zuck got his advertising check, and I got a new hobby. And for all that has been blamed on the internet, I owe it everything. Everything that I love doing, I have learned to some extent from the internet, whether it be the web development skills that I built exegesis with, my amateur interest in philosophy, my childhood love for art, or my newfound interest in guitar. I believe it is mankind's most beautiful invention.", "parent": "Giant Robots.txt", "score": 0.5529240369796753}, {"content": "Users should have complete control over what they see. I'm not saying algorithmic feeds don't have their place, but they should be something users opt in to. Andy [[Matuschak]] coined the idea of \"[programmable attention](https://notes.andymatuschak.org/zJrfPCbY7GcpV9asEc8NTVzXTAV4TvRFMuY6)\" as something [[tools for thought]] could enable. I will say that this already exists, only in the opposite, sinister sense - right now it's the platform programming your attention, not you. ", "parent": "Controlling what you see.txt", "score": 0.582960847736535}, {"content": "I'm convinced that algorithmic feeds are poisonous. Algorithmic feeds in apps are like cocaine in old medicines or asbestos in buildings, and someday they'll be seen to be just as barbaric.", "parent": "Controlling what you see.txt", "score": 0.6186787342626605}, {"content": "Here's a radical statement: All applications should be tools for thought. Facebook should be a tool for keeping up with friends, Instagram should be a tool for browsing and sharing photographs. [[tools for thought]] [[Manifesto]] ", "parent": "Controlling what you see.txt", "score": 0.6258497069690081}, {"content": "Upset at this state of affairs, I found [a chrome extension](https://chrome.google.com/webstore/detail/news-feed-eradicator/fjcldmjmjhkklehbacihaiopjklihlgg?hl=en) that disabled the \"feeds\" on a number of sites (Facebook, Youtube, LinkedIn, even HackerNews). This helped immediately. The unconscious, muscle-memory impulse to press Y and autocomplete into Youtube was still there, but when I opened the page, the algorithmic suggestions were all gone. Staring at the blank space, I would realize that I hadn't opened Youtube because I really wanted to watch anything, I had opened it because it was my impulse to do that while bored. ", "parent": "Controlling what you see.txt", "score": 0.6399263764388041}, {"content": "I spend an inordinate amount of time on Youtube. Having noticed this one morning, I quietly told myself that I wouldn't check Youtube for the rest of the work session - only to find that I would unconsciously press \"Y+enter\" and let the address bar's autocomplete lead me to Youtube. I would find myself on the site, not remembering how I had gotten there. More importantly, the home page recommendations had learned my preferences incredibly well. As soon as I landed on Youtube, there would be at least one video there ready for me to watch. That morning, I got nothing done. Youtube's algorithm had figured out that I really liked watching short clips of Mad Men and provided me a steady drip-feed of them, which I gorged on instead of getting anything done. ", "parent": "Controlling what you see.txt", "score": 0.6814606189727783}, {"content": "I don't think it's possible to fix our information ecosystem. In fact, I don't even know if it'd be desirable to fix it - as perverse as it is, there is also a chaotically beautiful side to the internet.", "parent": "Giant Robots.txt", "score": 0.6895720958709717}], "// Technology that you control": [{"content": "Users should have complete control over what they see. I'm not saying algorithmic feeds don't have their place, but they should be something users opt in to. Andy [[Matuschak]] coined the idea of \"[programmable attention](https://notes.andymatuschak.org/zJrfPCbY7GcpV9asEc8NTVzXTAV4TvRFMuY6)\" as something [[tools for thought]] could enable. I will say that this already exists, only in the opposite, sinister sense - right now it's the platform programming your attention, not you. ", "parent": "Controlling what you see.txt", "score": 0.7066919666321236}, {"content": "If you think about that a bit, it's a very quaint idea. Can you imagine a world where technology has developed to the point where we have giant robots, but technology is not somehow advanced enough to autopilot them? The idea seems strange to us, because in many respects, we live in a world diametrically opposed to the one portrayed in mecha science fiction. In their world, human beings control towering 50-foot humanoid war mechs. In ours, we are ruled by 5 inch screens in our pockets.", "parent": "Giant Robots.txt", "score": 0.7166471481323242}, {"content": "The problem with the view that technology is meant to solve problems is that technology always ends up doing so much more than that. Take any technology and its original intended purpose (fire, automobiles, airplanes, etc.) and you will find it has created a cascade of second order effects far beyond what it was originally intended to do. Sometimes these impacts are good, sometimes they're bad, sometimes they're just strange. ", "parent": "Creating new kinds of people.txt", "score": 0.7325735092163086}, {"content": "A point worth repeating: in mecha fiction, we control 50-foot-tall war robots, in our world, we are controlled by the 5 inch screens in our pocket.", "parent": "Giant Robots.txt", "score": 0.7454329133033752}, {"content": "The usual way to think about technology, software, and startups is that they solve problems, and so it follows then that the best way to create a new technology is to find a problem people have and solve it. This is not a bad approach to take, and it's been successful for many people. Still, I think it's too narrow.", "parent": "Creating new kinds of people.txt", "score": 0.7515028119087219}, {"content": "I desperately want programming to feel like this.", "parent": "Fragments.txt", "score": 0.7595077753067017}, {"content": "My hope is that local-first AI and CRDTs enable us to create decentralized, local first software that will stand the tests of time. This is why I'm so bullish on local first applications, plain text, file systems, and unix - they have already stood the tests of time, and will likely continue to. They are deeply lindy in a way that mobile and cloud computing are not. ", "parent": "Generational Computing.txt", "score": 0.7641630633792464}, {"content": "~", "parent": "Fragments.txt", "score": 0.7687820792198181}, {"content": "~", "parent": "Fragments.txt", "score": 0.7687854766845703}, {"content": "~", "parent": "Fragments.txt", "score": 0.7687854766845703}], "I don't think it's possible to fix our information ecosystem. In fact, I don't even know if it'd be desirable to fix it - as perverse as it is, there is also a chaotically beautiful side to the internet.": [{"content": "I don't think it's possible to fix our information ecosystem. In fact, I don't even know if it'd be desirable to fix it - as perverse as it is, there is also a chaotically beautiful side to the internet.", "parent": "Giant Robots.txt", "score": 1.4901161193847656e-06}, {"content": "Instead of fixing the information ecosystem, we should build tools that help us navigate it - to minimize the deleterious effects, and amplify the benefits. The antidote to an information ecosystem beyond our personal control is to create robust tools for information consumption and information processing that we can control.", "parent": "Giant Robots.txt", "score": 0.3490910530090332}, {"content": "If the internet is a hurricane of information, let us build steely exoskeletons to weather the storm.", "parent": "Giant Robots.txt", "score": 0.5672367215156555}, {"content": "Users should have complete control over what they see. I'm not saying algorithmic feeds don't have their place, but they should be something users opt in to. Andy [[Matuschak]] coined the idea of \"[programmable attention](https://notes.andymatuschak.org/zJrfPCbY7GcpV9asEc8NTVzXTAV4TvRFMuY6)\" as something [[tools for thought]] could enable. I will say that this already exists, only in the opposite, sinister sense - right now it's the platform programming your attention, not you. ", "parent": "Controlling what you see.txt", "score": 0.6043464345169856}, {"content": "I'm convinced that algorithmic feeds are poisonous. Algorithmic feeds in apps are like cocaine in old medicines or asbestos in buildings, and someday they'll be seen to be just as barbaric.", "parent": "Controlling what you see.txt", "score": 0.6348368545091649}, {"content": "To what degree can you control what you see on your phone? On any major social media site? The overwhelming trend of the last decade has been to replace user-controlled feeds with algorithmically curated ones. When you go to a newspaper stand, you pick which paper you'd like, which section you'd like to browse, and which article you'd like to read. When you open Facebook, what you see is decided for you by an algorithm mathematically optimized to maximize the amount of time you spend in the app. In the first scenario, the experience is like browsing a menu and ordering a meal. Choices are offered, a deliberation is made. In the second scenario, the content is slop, and the user is a pig eating it from a trough.", "parent": "Giant Robots.txt", "score": 0.6376053094863892}, {"content": "In my view, the whole movement of [[tools for thought]] (Roam, personal knowledge management systems, etc, etc.) is to make computers help us think better. That was the point from the very start, it was what Steve Jobs meant when he called the computer \"a bicycle for the mind.\" In the last decade, we've seen the very opposite - the use of the computer as an extractive tool, a weapon to siphon attention and harvest data. ", "parent": "Controlling what you see.txt", "score": 0.6558040285273536}, {"content": "Upset at this state of affairs, I found [a chrome extension](https://chrome.google.com/webstore/detail/news-feed-eradicator/fjcldmjmjhkklehbacihaiopjklihlgg?hl=en) that disabled the \"feeds\" on a number of sites (Facebook, Youtube, LinkedIn, even HackerNews). This helped immediately. The unconscious, muscle-memory impulse to press Y and autocomplete into Youtube was still there, but when I opened the page, the algorithmic suggestions were all gone. Staring at the blank space, I would realize that I hadn't opened Youtube because I really wanted to watch anything, I had opened it because it was my impulse to do that while bored. ", "parent": "Controlling what you see.txt", "score": 0.6568907148756069}, {"content": "With cloud software, our digital lives lack this permanence. Startups shut down left and right, products get split into multiple products or merged together, interfaces get redesigned and their redesigns get redesigned, all at the whims of the markets or feuding product managers. This is not a stable foundation to build anything lasting on top of.", "parent": "Generational Computing.txt", "score": 0.6574952828360243}, {"content": "The problem with the view that technology is meant to solve problems is that technology always ends up doing so much more than that. Take any technology and its original intended purpose (fire, automobiles, airplanes, etc.) and you will find it has created a cascade of second order effects far beyond what it was originally intended to do. Sometimes these impacts are good, sometimes they're bad, sometimes they're just strange. ", "parent": "Creating new kinds of people.txt", "score": 0.6743566989898682}], "Here's an anecdote to illustrate my point: I picked up guitar at the start of quarantine. What inspired this? Was it a childhood dream of mine? Maybe I wanted to be like my favorite rock stars? Or was it just the boredom?": [{"content": "Here's an anecdote to illustrate my point: I picked up guitar at the start of quarantine. What inspired this? Was it a childhood dream of mine? Maybe I wanted to be like my favorite rock stars? Or was it just the boredom?", "parent": "Giant Robots.txt", "score": -1.1920928955078125e-07}, {"content": "I fell in love with playing the guitar because it rewards this lack of an attention span. You can copy a riff in minutes. You can create a new riff in minutes. Picking up a guitar puts me in an instant flow state, because I can just screw around and play with ideas instantly. It feels like a REPL for musical ideas.", "parent": "Fragments.txt", "score": 0.44582265615463257}, {"content": "None of the above. I got a targeted Facebook ad for Fender's free online guitar course. I remember this very distinctly as the moment I decided to learn guitar; I had never really thought much about it at all before that. Deep within the entrails of Facebook's recommendation engine, some algorithm made an educated guess that I'd enjoy picking up the guitar - and it was right. For all the horrible things Facebook has done, this was a real positive-sum, Pareto optimal moment. Zuck got his advertising check, and I got a new hobby. And for all that has been blamed on the internet, I owe it everything. Everything that I love doing, I have learned to some extent from the internet, whether it be the web development skills that I built exegesis with, my amateur interest in philosophy, my childhood love for art, or my newfound interest in guitar. I believe it is mankind's most beautiful invention.", "parent": "Giant Robots.txt", "score": 0.5025185942649841}, {"content": "I think it's important to have free time to just mess around and be bored, and explore dumb things that might turn out to be not so dumb - after all, \"boredom is that disagreeable 'windless calm' of the soul that precedes a happy voyage and cheerful winds.\" Every activity I eventually took seriously - Model UN in high school, programming in college - started out as an casual hobby I never planned to take seriously. So, I'd rather have slow progress towards my goals and a sizeable chunk of time to mess around, than to fill my days to the point where I have no time to explore at all.", "parent": "Goals for Spring Quarter.txt", "score": 0.5686901817722716}, {"content": "I have not really settled into a good practice schedule for either piano or guitar. For the past couple of weeks, I've neglected guitar after moving my electric keyboard into my room, though my piano progress has hardly been good either - I have spent the past couple months playing the same pentatonic licks over Autumn Leaves. My goal for both instruments is to learn a couple of jazz standards with my housemates so we can jam together more. ", "parent": "Goals for Spring Quarter.txt", "score": 0.5805310611872798}, {"content": "Growing up, my main creative outlet was drawing. As soon as a pencil or pen touched my hand I would have to draw something - it was almost involuntary. Many school notebooks were ruined this way, many concerned teachers advised me to keep my homework free of doodles.", "parent": "Fragments.txt", "score": 0.600963830947876}, {"content": "Something weird is happening here - we have access to more music and genres than ever before in human history, and yet it feels like something important is missing. Many of the people I talk to listen to music all the time, but I get the sense that it's more to ward off the dreaded experience of silence than it is to actually enjoy music. ", "parent": "Context and community makes music more enjoyable, and it's missing from modern streaming services.txt", "score": 0.6124445796012878}, {"content": "As far as a schedule goes, I'd like to learn something new on the piano/guitar (either online lessons or part of a song) at least twice a week (for each instrument). Noodling doesn't count towards this goal. For the harmonica, I'm working my way through some Youtube course I found, and I'd like to work through at least one lesson a week.", "parent": "Goals for Spring Quarter.txt", "score": 0.6186439519004268}, {"content": "As mentioned earlier, the modern experience of listening to music alone is completely novel - before technology, listening to music was always a social affair, unless you were playing music for yourself. ", "parent": "Context and community makes music more enjoyable, and it's missing from modern streaming services.txt", "score": 0.6281492710113525}, {"content": "Here's another difference between the way we experience music and the way our ancestors did: it used to be the case that music was almost always a social experience. Before technology, if you wanted to listen to music, someone had to play music. It was a special, ceremonious event. The modern experience of listening to music alone, all the time would have been incomprehensible to our ancestors. ", "parent": "Context and community makes music more enjoyable, and it's missing from modern streaming services.txt", "score": 0.6310716271400452}], "None of the above. I got a targeted Facebook ad for Fender's free online guitar course. I remember this very distinctly as the moment I decided to learn guitar; I had never really thought much about it at all before that. Deep within the entrails of Facebook's recommendation engine, some algorithm made an educated guess that I'd enjoy picking up the guitar - and it was right. For all the horrible things Facebook has done, this was a real positive-sum, Pareto optimal moment. Zuck got his advertising check, and I got a new hobby. And for all that has been blamed on the internet, I owe it everything. Everything that I love doing, I have learned to some extent from the internet, whether it be the web development skills that I built exegesis with, my amateur interest in philosophy, my childhood love for art, or my newfound interest in guitar. I believe it is mankind's most beautiful invention.": [{"content": "None of the above. I got a targeted Facebook ad for Fender's free online guitar course. I remember this very distinctly as the moment I decided to learn guitar; I had never really thought much about it at all before that. Deep within the entrails of Facebook's recommendation engine, some algorithm made an educated guess that I'd enjoy picking up the guitar - and it was right. For all the horrible things Facebook has done, this was a real positive-sum, Pareto optimal moment. Zuck got his advertising check, and I got a new hobby. And for all that has been blamed on the internet, I owe it everything. Everything that I love doing, I have learned to some extent from the internet, whether it be the web development skills that I built exegesis with, my amateur interest in philosophy, my childhood love for art, or my newfound interest in guitar. I believe it is mankind's most beautiful invention.", "parent": "Giant Robots.txt", "score": -7.152557373046875e-07}, {"content": "Here's an anecdote to illustrate my point: I picked up guitar at the start of quarantine. What inspired this? Was it a childhood dream of mine? Maybe I wanted to be like my favorite rock stars? Or was it just the boredom?", "parent": "Giant Robots.txt", "score": 0.5025663375854492}, {"content": "Upset at this state of affairs, I found [a chrome extension](https://chrome.google.com/webstore/detail/news-feed-eradicator/fjcldmjmjhkklehbacihaiopjklihlgg?hl=en) that disabled the \"feeds\" on a number of sites (Facebook, Youtube, LinkedIn, even HackerNews). This helped immediately. The unconscious, muscle-memory impulse to press Y and autocomplete into Youtube was still there, but when I opened the page, the algorithmic suggestions were all gone. Staring at the blank space, I would realize that I hadn't opened Youtube because I really wanted to watch anything, I had opened it because it was my impulse to do that while bored. ", "parent": "Controlling what you see.txt", "score": 0.5070772044767692}, {"content": "I spend an inordinate amount of time on Youtube. Having noticed this one morning, I quietly told myself that I wouldn't check Youtube for the rest of the work session - only to find that I would unconsciously press \"Y+enter\" and let the address bar's autocomplete lead me to Youtube. I would find myself on the site, not remembering how I had gotten there. More importantly, the home page recommendations had learned my preferences incredibly well. As soon as I landed on Youtube, there would be at least one video there ready for me to watch. That morning, I got nothing done. Youtube's algorithm had figured out that I really liked watching short clips of Mad Men and provided me a steady drip-feed of them, which I gorged on instead of getting anything done. ", "parent": "Controlling what you see.txt", "score": 0.5154763460159302}, {"content": "I fell in love with playing the guitar because it rewards this lack of an attention span. You can copy a riff in minutes. You can create a new riff in minutes. Picking up a guitar puts me in an instant flow state, because I can just screw around and play with ideas instantly. It feels like a REPL for musical ideas.", "parent": "Fragments.txt", "score": 0.5433627367019653}, {"content": "Who cares? Make all the metaphysical arguments you'd like, a sufficiently powerful recommendation algorithm will still be able to sway decisions enough for Facebook to make 86 billion dollars a year. Free will may or may not be real, but it is an empirical fact that the profitable choice is to act as if it isn't.", "parent": "Giant Robots.txt", "score": 0.5529100894927979}, {"content": "To what degree can you control what you see on your phone? On any major social media site? The overwhelming trend of the last decade has been to replace user-controlled feeds with algorithmically curated ones. When you go to a newspaper stand, you pick which paper you'd like, which section you'd like to browse, and which article you'd like to read. When you open Facebook, what you see is decided for you by an algorithm mathematically optimized to maximize the amount of time you spend in the app. In the first scenario, the experience is like browsing a menu and ordering a meal. Choices are offered, a deliberation is made. In the second scenario, the content is slop, and the user is a pig eating it from a trough.", "parent": "Giant Robots.txt", "score": 0.5578029155731201}, {"content": "Here's a radical statement: All applications should be tools for thought. Facebook should be a tool for keeping up with friends, Instagram should be a tool for browsing and sharing photographs. [[tools for thought]] [[Manifesto]] ", "parent": "Controlling what you see.txt", "score": 0.5596784030918083}, {"content": "But the user has chosen to open Facebook, and chosen to sign up for the service. Isn't this a philosophical question about choice? Isn't free will real? ", "parent": "Giant Robots.txt", "score": 0.5649392604827881}, {"content": "There is a particular kind of second order effect that is of special interest: technologies can create entire new types of people. Instagram created the influencer, Youtube produced the Youtuber, Soundcloud spawned its own eponymous kind of rapper. The more extreme political factions in America trace their lineages to 4Chan and Tumblr. To give an older example, the factory birthed the proletariat a century ago. ", "parent": "Creating new kinds of people.txt", "score": 0.5705737471580505}], "Instead of fixing the information ecosystem, we should build tools that help us navigate it - to minimize the deleterious effects, and amplify the benefits. The antidote to an information ecosystem beyond our personal control is to create robust tools for information consumption and information processing that we can control.": [{"content": "Instead of fixing the information ecosystem, we should build tools that help us navigate it - to minimize the deleterious effects, and amplify the benefits. The antidote to an information ecosystem beyond our personal control is to create robust tools for information consumption and information processing that we can control.", "parent": "Giant Robots.txt", "score": 1.1920928955078125e-06}, {"content": "I don't think it's possible to fix our information ecosystem. In fact, I don't even know if it'd be desirable to fix it - as perverse as it is, there is also a chaotically beautiful side to the internet.", "parent": "Giant Robots.txt", "score": 0.3490944504737854}, {"content": "If the internet is a hurricane of information, let us build steely exoskeletons to weather the storm.", "parent": "Giant Robots.txt", "score": 0.5100108981132507}, {"content": "In my view, the whole movement of [[tools for thought]] (Roam, personal knowledge management systems, etc, etc.) is to make computers help us think better. That was the point from the very start, it was what Steve Jobs meant when he called the computer \"a bicycle for the mind.\" In the last decade, we've seen the very opposite - the use of the computer as an extractive tool, a weapon to siphon attention and harvest data. ", "parent": "Controlling what you see.txt", "score": 0.5174656393907224}, {"content": "Users should have complete control over what they see. I'm not saying algorithmic feeds don't have their place, but they should be something users opt in to. Andy [[Matuschak]] coined the idea of \"[programmable attention](https://notes.andymatuschak.org/zJrfPCbY7GcpV9asEc8NTVzXTAV4TvRFMuY6)\" as something [[tools for thought]] could enable. I will say that this already exists, only in the opposite, sinister sense - right now it's the platform programming your attention, not you. ", "parent": "Controlling what you see.txt", "score": 0.5389324171442658}, {"content": "To what degree can you control what you see on your phone? On any major social media site? The overwhelming trend of the last decade has been to replace user-controlled feeds with algorithmically curated ones. When you go to a newspaper stand, you pick which paper you'd like, which section you'd like to browse, and which article you'd like to read. When you open Facebook, what you see is decided for you by an algorithm mathematically optimized to maximize the amount of time you spend in the app. In the first scenario, the experience is like browsing a menu and ordering a meal. Choices are offered, a deliberation is made. In the second scenario, the content is slop, and the user is a pig eating it from a trough.", "parent": "Giant Robots.txt", "score": 0.5851033926010132}, {"content": "Here's a radical statement: All applications should be tools for thought. Facebook should be a tool for keeping up with friends, Instagram should be a tool for browsing and sharing photographs. [[tools for thought]] [[Manifesto]] ", "parent": "Controlling what you see.txt", "score": 0.6004437246847838}, {"content": "I want digital technology to bridge divides between generations instead of widening them. I want it to foster remembrance instead of forgetting. I want it to reward thinking multiple generations into the future instead of until the end of the quarter.", "parent": "Generational Computing.txt", "score": 0.6165180483074811}, {"content": "The usual way to think about technology, software, and startups is that they solve problems, and so it follows then that the best way to create a new technology is to find a problem people have and solve it. This is not a bad approach to take, and it's been successful for many people. Still, I think it's too narrow.", "parent": "Creating new kinds of people.txt", "score": 0.6366012096405029}, {"content": "With cloud software, our digital lives lack this permanence. Startups shut down left and right, products get split into multiple products or merged together, interfaces get redesigned and their redesigns get redesigned, all at the whims of the markets or feuding product managers. This is not a stable foundation to build anything lasting on top of.", "parent": "Generational Computing.txt", "score": 0.6376406856138596}], "If the internet is a hurricane of information, let us build steely exoskeletons to weather the storm.": [{"content": "If the internet is a hurricane of information, let us build steely exoskeletons to weather the storm.", "parent": "Giant Robots.txt", "score": -3.5762786865234375e-07}, {"content": "Instead of fixing the information ecosystem, we should build tools that help us navigate it - to minimize the deleterious effects, and amplify the benefits. The antidote to an information ecosystem beyond our personal control is to create robust tools for information consumption and information processing that we can control.", "parent": "Giant Robots.txt", "score": 0.5100157856941223}, {"content": "I don't think it's possible to fix our information ecosystem. In fact, I don't even know if it'd be desirable to fix it - as perverse as it is, there is also a chaotically beautiful side to the internet.", "parent": "Giant Robots.txt", "score": 0.5672270059585571}, {"content": "In my view, the whole movement of [[tools for thought]] (Roam, personal knowledge management systems, etc, etc.) is to make computers help us think better. That was the point from the very start, it was what Steve Jobs meant when he called the computer \"a bicycle for the mind.\" In the last decade, we've seen the very opposite - the use of the computer as an extractive tool, a weapon to siphon attention and harvest data. ", "parent": "Controlling what you see.txt", "score": 0.5922936385568949}, {"content": "With cloud software, our digital lives lack this permanence. Startups shut down left and right, products get split into multiple products or merged together, interfaces get redesigned and their redesigns get redesigned, all at the whims of the markets or feuding product managers. This is not a stable foundation to build anything lasting on top of.", "parent": "Generational Computing.txt", "score": 0.6266273348531208}, {"content": "Users should have complete control over what they see. I'm not saying algorithmic feeds don't have their place, but they should be something users opt in to. Andy [[Matuschak]] coined the idea of \"[programmable attention](https://notes.andymatuschak.org/zJrfPCbY7GcpV9asEc8NTVzXTAV4TvRFMuY6)\" as something [[tools for thought]] could enable. I will say that this already exists, only in the opposite, sinister sense - right now it's the platform programming your attention, not you. ", "parent": "Controlling what you see.txt", "score": 0.6429502954837776}, {"content": "My dream is to enable something I term \"generational computing.\" I want my kids and my grandkids to someday be able to interface with the artifacts of my digital life. I want them to be able to read my notes and ask an LLM about what I've learned over my life. I want them to be able to chat with a replica of me trained on my writings. I want them to be able to look through the music I made and the music I listened to, and see the connections between the two. I want them to be able to upload their own musical ideas or writings, and see the connections between what they've made and what I've made. ", "parent": "Generational Computing.txt", "score": 0.6437080507817557}, {"content": "If you think about that a bit, it's a very quaint idea. Can you imagine a world where technology has developed to the point where we have giant robots, but technology is not somehow advanced enough to autopilot them? The idea seems strange to us, because in many respects, we live in a world diametrically opposed to the one portrayed in mecha science fiction. In their world, human beings control towering 50-foot humanoid war mechs. In ours, we are ruled by 5 inch screens in our pockets.", "parent": "Giant Robots.txt", "score": 0.6499955654144287}, {"content": "A point worth repeating: in mecha fiction, we control 50-foot-tall war robots, in our world, we are controlled by the 5 inch screens in our pocket.", "parent": "Giant Robots.txt", "score": 0.6670737266540527}, {"content": "Here's a radical statement: All applications should be tools for thought. Facebook should be a tool for keeping up with friends, Instagram should be a tool for browsing and sharing photographs. [[tools for thought]] [[Manifesto]] ", "parent": "Controlling what you see.txt", "score": 0.6722176807292581}]}