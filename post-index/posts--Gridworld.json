{"I've vacillated on this blog between the idea of working on small projects and working on large projects. I thought I'd try something of a hybrid approach - having a main project, and then working on spinoff projects when I need a break. I spent last week working on such a project.": [{"content": "I've vacillated on this blog between the idea of working on small projects and working on large projects. I thought I'd try something of a hybrid approach - having a main project, and then working on spinoff projects when I need a break. I spent last week working on such a project.", "parent": "Gridworld.txt", "score": 5.435866937686384e-07}, {"content": "The good news is I've found a method of working on side projects that does work for me: working on one side project at a time, with the intention of getting real users. This is a way of working I previously tried explicitly to steer away from - I've written previously on my blog that I wanted to work on lots of small projects instead of obsessively on one big project. ", "parent": "An Update.txt", "score": 0.315138041973114}, {"content": "The previous method of working I sketched out in this blog (working on small projects, writing about them in public) is not working for me. It was working for me for a while, mostly while I was building at the Recurse center, but it's not anymore, and it's because I just don't feel motivated to work on lots of small projects that no one uses. ", "parent": "An Update.txt", "score": 0.3336032032966614}, {"content": "Reflecting on how this went, I'm glad I branched out into another project, but I honestly don't really care about Gridworld all that much. It feels disconnected from everything else I made and I'm not super interested in following up more on it. I think the approach of working on one main project with breaks to work on smaller projects is a good one, but I want those smaller projects to be more related to my main project. I have lots of side project ideas related to tools for thought and music. I thought it'd be cool to do LLM research for its own sake, but I've realized I don't care all that much about the fundamental properties of LLMs - I care more about using them as a tool to build the things I already want to build. There are plenty of possibilities there, for example adding semantic search to Synesthesia to supplement the tagging system (which I honestly do not like at all). As I continue to build side projects in my spare time I want to keep this in mind.", "parent": "Gridworld.txt", "score": 0.37259835737520053}, {"content": "The idea is to just make a ton of side projects and put them all here. I have some preliminary ideas on how I can organize this but I'm not particularly set on anything right now. I don't feel particularly limited by framework choice either - with the liberal use of iFrames, I can simply embed other projects using different frameworks here. I've already done that with a project I've created with Svelte.", "parent": "Fragments.txt", "score": 0.44285303354263306}, {"content": "The main focus here is personal projects - learning more code and writing more are auxiliary activities that help this end. First among these personal projects is [[exegesis]], but I have a number of other personal projects that I want to work on as well. ", "parent": "Goals for Spring Quarter.txt", "score": 0.4473820924758911}, {"content": "I've found writing down tasks and decomposing them into smaller ones helps. Right now, I do this in [[exegesis]], which honestly feels somewhat suboptimal. I also have another side project called [https://focusmachine.app/](https://focusmachine.app/) to remind me of what I'm currently supposed to be focusing - it's really stupid, it just asks you what you want to work on and then spams you with a reminder to focus on that at user-inputted interval. [[focus]] [[focus-machine]] [[ideas]] [[exegesis]] ", "parent": "untitled-9-24-2021.txt", "score": 0.4503380060195923}, {"content": "Working on a refactor for [[exegesis]] and [[synesthesia]], thinking about how to budget time. Working strategy is to take estimate for each feature, and double the time for each to account for stupid roadblocks (wifi not working, interrupted by something, bad documentation, etc. etc.) [[code]] [[devlog]] ", "parent": "untitled-9-21-2021.txt", "score": 0.4737289547920227}, {"content": "I want to try a different approach this time. There will be no central organizing idea or principle. Playing the guitar taught me that my creative process works best when I'm free to noodle on the ideas that are immediately interesting to me, not ideas that are part of some preset plan. I have fond memories of sitting on the bus back from my first internship, cracking open my laptop, deciding to try and hack together a first version of YANA. I feel considerably less nostalgic for the late nights I spent during the pandemic trying to \"scale\" my idea, wrestling with pitch decks and AWS dashboards. I had lots of other ideas at the time, but didn't work on them because I felt focusing on exegesis was the correct thing to do. When I first started playing the guitar, I felt guilty learning other songs if I hadn't finished learning a past song. In reality, giving up on songs/concepts I wasn't interested in was incredibly good for my learning in the long run (provided I was still learning new things).", "parent": "Interface Work.txt", "score": 0.48431849479675293}, {"content": "For a while, I exclusively worked on a long, serious projects. I wanted to build a billion dollar product. I wanted to be the founder of a successful startup. I wanted to write, but I wanted to write on my own platform that everybody else would also write on, that would have all the features I wanted that everybody else would love.", "parent": "Fragments.txt", "score": 0.48988139629364014}], "": [{"content": "~", "parent": "NOW PAGE.txt", "score": 0.6013319492340088}, {"content": "~", "parent": "Fragments.txt", "score": 0.6013319492340088}, {"content": "~", "parent": "Fragments.txt", "score": 0.6013319492340088}, {"content": "~", "parent": "Plaintext is your best friend.txt", "score": 0.6013771295547485}, {"content": "~", "parent": "untitled-1-4-2022.txt", "score": 0.6013792157173157}, {"content": "~", "parent": "The making of Nomad Hypertext.txt", "score": 0.6014099717140198}, {"content": "~", "parent": "The making of Nomad Hypertext.txt", "score": 0.6014099717140198}, {"content": "~", "parent": "Second Brains.txt", "score": 0.6014099717140198}, {"content": "~", "parent": "What is Nomad Hypertext.txt", "score": 0.6014099717140198}, {"content": "~", "parent": "What is Nomad Hypertext.txt", "score": 0.6014099717140198}], "[Gridworld](https://gridworld.nicholaschen.io) is a turn-based, LLM-based, grid-based world simulator. ": [{"content": "[Gridworld](https://gridworld.nicholaschen.io) is a turn-based, LLM-based, grid-based world simulator. ", "parent": "Gridworld.txt", "score": 5.039119854721719e-07}, {"content": "One fun thing about this project is it made me think a lot about grids. Grids are cool! You can use them in lots of unorthodox ways. I saw [Clavier36](https://clavier36.com/) while working on Gridworld and it made me wonder what a similar interface for composing prompts might look like.  ", "parent": "Gridworld.txt", "score": 0.45109066395272357}, {"content": "The core game loop looks like this: At the end of each turn, extract all agents from the board (by finding cells that contain text that matches <agent>). For each agent, plot what action to take, given the current board state and the agent's past history. Then, for the grid as a whole, consider any environmental affects that might happen (fire spreading, rivers flowing, etc). Finally, given all agent actions and environmental affects, decide the next state of the grid.", "parent": "Gridworld.txt", "score": 0.547066239126123}, {"content": "Reflecting on how this went, I'm glad I branched out into another project, but I honestly don't really care about Gridworld all that much. It feels disconnected from everything else I made and I'm not super interested in following up more on it. I think the approach of working on one main project with breaks to work on smaller projects is a good one, but I want those smaller projects to be more related to my main project. I have lots of side project ideas related to tools for thought and music. I thought it'd be cool to do LLM research for its own sake, but I've realized I don't care all that much about the fundamental properties of LLMs - I care more about using them as a tool to build the things I already want to build. There are plenty of possibilities there, for example adding semantic search to Synesthesia to supplement the tagging system (which I honestly do not like at all). As I continue to build side projects in my spare time I want to keep this in mind.", "parent": "Gridworld.txt", "score": 0.5606955544530019}, {"content": "I was drawn to the idea of a simple world state - a simple two dimensional array of text. I figured it would be difficult for the LLM to simulate convincing theory of mind (e.g. agents can plot against other agents without the other agents knowing )with just a 2D grid, so I added additional state to simulate the memory and thought process of agents. In practice, this is all very simple as well - it's just an array of text, representing the agent's past thought processes.", "parent": "Gridworld.txt", "score": 0.5903586489350019}, {"content": "The core game state is just a grid of strings. You can denominate agents like so - <agent>. Agents have their own internal thought processes and planning stage at the end of each turn. ", "parent": "Gridworld.txt", "score": 0.6183076430403407}, {"content": "In practice, I had to add quite a few \"proofreading\" steps and some bespoke logic to spot invalid game states - agents suddenly disappearing from the grid, agents suddenly jumping across the map, agents showing up twice because the world reconciliation step didn't erase the agent's previous position, etc.", "parent": "Gridworld.txt", "score": 0.6271182471436767}, {"content": "My motivation for working on this project was to explore the frame of LLMs as simulators. Could you use LLMs to simulate how multiple agents interact with each other in a given scenario?", "parent": "Gridworld.txt", "score": 0.6292367876951642}, {"content": "This site will be that infrastructure for me. It will be a place for me to play with ideas quickly.", "parent": "Fragments.txt", "score": 0.666196346282959}, {"content": "rhizome.world", "parent": "untitled-9-24-2021.txt", "score": 0.6720868349075317}], "The core game state is just a grid of strings. You can denominate agents like so - <agent>. Agents have their own internal thought processes and planning stage at the end of each turn. ": [{"content": "The core game state is just a grid of strings. You can denominate agents like so - <agent>. Agents have their own internal thought processes and planning stage at the end of each turn. ", "parent": "Gridworld.txt", "score": 4.148623065081125e-07}, {"content": "The core game loop looks like this: At the end of each turn, extract all agents from the board (by finding cells that contain text that matches <agent>). For each agent, plot what action to take, given the current board state and the agent's past history. Then, for the grid as a whole, consider any environmental affects that might happen (fire spreading, rivers flowing, etc). Finally, given all agent actions and environmental affects, decide the next state of the grid.", "parent": "Gridworld.txt", "score": 0.26644169034527654}, {"content": "I was drawn to the idea of a simple world state - a simple two dimensional array of text. I figured it would be difficult for the LLM to simulate convincing theory of mind (e.g. agents can plot against other agents without the other agents knowing )with just a 2D grid, so I added additional state to simulate the memory and thought process of agents. In practice, this is all very simple as well - it's just an array of text, representing the agent's past thought processes.", "parent": "Gridworld.txt", "score": 0.31116058835274274}, {"content": "In practice, I had to add quite a few \"proofreading\" steps and some bespoke logic to spot invalid game states - agents suddenly disappearing from the grid, agents suddenly jumping across the map, agents showing up twice because the world reconciliation step didn't erase the agent's previous position, etc.", "parent": "Gridworld.txt", "score": 0.43625951234417093}, {"content": "[Gridworld](https://gridworld.nicholaschen.io) is a turn-based, LLM-based, grid-based world simulator. ", "parent": "Gridworld.txt", "score": 0.618296739353939}, {"content": "[People have researched this topic in the past.](https://arxiv.org/pdf/2304.03442) Usually, however, they've used fairly complicated world simulators and agent loops. Given vast improvements in model quality, is it possible to eschew this programmatic scaffolding in favor of something simpler? This seems to be a general trend with language models - as base models improve, the amount of programmatic \"scaffolding\" you need around them decreases. For example, as context windows have increased, RAG is used less often. You can skip the overhead of spinning up a vector database in favor of just stuffing all your context into the prompt.", "parent": "Gridworld.txt", "score": 0.6284720599639151}, {"content": "One fun thing about this project is it made me think a lot about grids. Grids are cool! You can use them in lots of unorthodox ways. I saw [Clavier36](https://clavier36.com/) while working on Gridworld and it made me wonder what a similar interface for composing prompts might look like.  ", "parent": "Gridworld.txt", "score": 0.6544964818075778}, {"content": "My motivation for working on this project was to explore the frame of LLMs as simulators. Could you use LLMs to simulate how multiple agents interact with each other in a given scenario?", "parent": "Gridworld.txt", "score": 0.657547134821524}, {"content": "Psychology, ethics, and game theory are diverse fields that all point towards blindness being situationally useful. All fields relate to human action, so maybe it's possible to generalize this on that level. ", "parent": "Strategic blindness.txt", "score": 0.6685423851013184}, {"content": "That makes the answer to the question, \"Can you get rid of scaffolding in favor of just relying on the base model?\" a resounding no. The models really struggle with maintaining object permanence. You need to model this programmatically - even if the context window is large enough to store a world model, the LLM itself hallucinates too often to maintain coherence over multiple turns.", "parent": "Gridworld.txt", "score": 0.6783787671334514}], "My motivation for working on this project was to explore the frame of LLMs as simulators. Could you use LLMs to simulate how multiple agents interact with each other in a given scenario?": [{"content": "My motivation for working on this project was to explore the frame of LLMs as simulators. Could you use LLMs to simulate how multiple agents interact with each other in a given scenario?", "parent": "Gridworld.txt", "score": 0.0}, {"content": "I was drawn to the idea of a simple world state - a simple two dimensional array of text. I figured it would be difficult for the LLM to simulate convincing theory of mind (e.g. agents can plot against other agents without the other agents knowing )with just a 2D grid, so I added additional state to simulate the memory and thought process of agents. In practice, this is all very simple as well - it's just an array of text, representing the agent's past thought processes.", "parent": "Gridworld.txt", "score": 0.4532905262321635}, {"content": "[People have researched this topic in the past.](https://arxiv.org/pdf/2304.03442) Usually, however, they've used fairly complicated world simulators and agent loops. Given vast improvements in model quality, is it possible to eschew this programmatic scaffolding in favor of something simpler? This seems to be a general trend with language models - as base models improve, the amount of programmatic \"scaffolding\" you need around them decreases. For example, as context windows have increased, RAG is used less often. You can skip the overhead of spinning up a vector database in favor of just stuffing all your context into the prompt.", "parent": "Gridworld.txt", "score": 0.5567196444868661}, {"content": "Reflecting on how this went, I'm glad I branched out into another project, but I honestly don't really care about Gridworld all that much. It feels disconnected from everything else I made and I'm not super interested in following up more on it. I think the approach of working on one main project with breaks to work on smaller projects is a good one, but I want those smaller projects to be more related to my main project. I have lots of side project ideas related to tools for thought and music. I thought it'd be cool to do LLM research for its own sake, but I've realized I don't care all that much about the fundamental properties of LLMs - I care more about using them as a tool to build the things I already want to build. There are plenty of possibilities there, for example adding semantic search to Synesthesia to supplement the tagging system (which I honestly do not like at all). As I continue to build side projects in my spare time I want to keep this in mind.", "parent": "Gridworld.txt", "score": 0.5704500542097131}, {"content": "In practice, I had to add quite a few \"proofreading\" steps and some bespoke logic to spot invalid game states - agents suddenly disappearing from the grid, agents suddenly jumping across the map, agents showing up twice because the world reconciliation step didn't erase the agent's previous position, etc.", "parent": "Gridworld.txt", "score": 0.591389953060119}, {"content": "That makes the answer to the question, \"Can you get rid of scaffolding in favor of just relying on the base model?\" a resounding no. The models really struggle with maintaining object permanence. You need to model this programmatically - even if the context window is large enough to store a world model, the LLM itself hallucinates too often to maintain coherence over multiple turns.", "parent": "Gridworld.txt", "score": 0.6074816064690001}, {"content": "[Gridworld](https://gridworld.nicholaschen.io) is a turn-based, LLM-based, grid-based world simulator. ", "parent": "Gridworld.txt", "score": 0.6292489132278223}, {"content": "I've had some spirited debates on this subject, most recently with [[Jared]] of [[hyperlink-academy]]. I personally believe this is possible, but I've also heard very good arguments otherwise. The synthesis in my head is currently this: the instructor/student relationship is not neccessary, but a social learning environment is. To improve at something, we need to be around people better than ourselves, and a certain level of humility is required to learn from those better than ourselves. An instructor/student relationship is an institutionalized way to approximate this; how effective it is depends on the quality of the institution. I don't think it's the only way to achieve this however, and there are interesting experiments in cohort-based learning that could illustrate other ways to provide a social learning environment.[[meta-acropolis]] [[ideas]] [[Jared]] [[hyperlink-academy]] ", "parent": "untitled-9-21-2021.txt", "score": 0.6293033361434937}, {"content": "My dream is to enable something I term \"generational computing.\" I want my kids and my grandkids to someday be able to interface with the artifacts of my digital life. I want them to be able to read my notes and ask an LLM about what I've learned over my life. I want them to be able to chat with a replica of me trained on my writings. I want them to be able to look through the music I made and the music I listened to, and see the connections between the two. I want them to be able to upload their own musical ideas or writings, and see the connections between what they've made and what I've made. ", "parent": "Generational Computing.txt", "score": 0.6342108249664307}, {"content": "The core game loop looks like this: At the end of each turn, extract all agents from the board (by finding cells that contain text that matches <agent>). For each agent, plot what action to take, given the current board state and the agent's past history. Then, for the grid as a whole, consider any environmental affects that might happen (fire spreading, rivers flowing, etc). Finally, given all agent actions and environmental affects, decide the next state of the grid.", "parent": "Gridworld.txt", "score": 0.6420324028247169}], "[People have researched this topic in the past.](https://arxiv.org/pdf/2304.03442) Usually, however, they've used fairly complicated world simulators and agent loops. Given vast improvements in model quality, is it possible to eschew this programmatic scaffolding in favor of something simpler? This seems to be a general trend with language models - as base models improve, the amount of programmatic \"scaffolding\" you need around them decreases. For example, as context windows have increased, RAG is used less often. You can skip the overhead of spinning up a vector database in favor of just stuffing all your context into the prompt.": [{"content": "[People have researched this topic in the past.](https://arxiv.org/pdf/2304.03442) Usually, however, they've used fairly complicated world simulators and agent loops. Given vast improvements in model quality, is it possible to eschew this programmatic scaffolding in favor of something simpler? This seems to be a general trend with language models - as base models improve, the amount of programmatic \"scaffolding\" you need around them decreases. For example, as context windows have increased, RAG is used less often. You can skip the overhead of spinning up a vector database in favor of just stuffing all your context into the prompt.", "parent": "Gridworld.txt", "score": 0.0}, {"content": "That makes the answer to the question, \"Can you get rid of scaffolding in favor of just relying on the base model?\" a resounding no. The models really struggle with maintaining object permanence. You need to model this programmatically - even if the context window is large enough to store a world model, the LLM itself hallucinates too often to maintain coherence over multiple turns.", "parent": "Gridworld.txt", "score": 0.45828000602994234}, {"content": "One downside of this approach is that it makes parallelizing summaries impossible. The context also tends to bloat, and pieces of context that aren't relevant anymore tend to stay in the context anyways. ", "parent": "Interface Journal: Summary Tool.txt", "score": 0.5148218870162964}, {"content": "The future of rational tools for thought and PKMs probably look a lot less like [[roam]], and [more like projects that use AI to automatically link subjects for you](https://thesephist.com/posts/browser/). 2", "parent": "On tools for thought: knowledge management vs creativity.txt", "score": 0.5174254179000854}, {"content": "However, when building Yurt, the static site builder for nomad hypertext, I found myself repeating a lot of logic. I found myself wanting to add features to the indexing engine, like being able to use cloud providers instead of local models (because doing all this processing locally can take ages!). In the future, I might want to use multimodal models, so I can see similarity between images, text, and audio. \n\nFactoring out the semantic search element of my app would have been the correct, unix-ey thing to do, and it would allow me to make these extensions in the future. I plan on doing this soon.  ", "parent": "The making of Nomad Hypertext.txt", "score": 0.53337562084198}, {"content": "I was drawn to the idea of a simple world state - a simple two dimensional array of text. I figured it would be difficult for the LLM to simulate convincing theory of mind (e.g. agents can plot against other agents without the other agents knowing )with just a 2D grid, so I added additional state to simulate the memory and thought process of agents. In practice, this is all very simple as well - it's just an array of text, representing the agent's past thought processes.", "parent": "Gridworld.txt", "score": 0.538019109076378}, {"content": "However, in practice that's kind of hard. One challenge is that a lot of functionality that could in practice be reusable sometimes has to be coupled into application logic - an example of this is the semantic search in Nomad Hypertext. It would be great if my (hypothetical) summarizer app could list out the themes I was writing about this week, and there was a modal where you could use semantic search to find all other instances in my notes where I've written about that theme. It would be even greater if I didn't have to rewrite all this from scratch. Unfortunately, since semantic search is baked into Nomad Hypertext as an application, not a separate service, I can't reuse that functionality super easily in another app.", "parent": "Interface Work: Stealth Button.txt", "score": 0.5419080257415771}, {"content": "My motivation for working on this project was to explore the frame of LLMs as simulators. Could you use LLMs to simulate how multiple agents interact with each other in a given scenario?", "parent": "Gridworld.txt", "score": 0.5567196444868661}, {"content": "Local-first AI presents a huge opportunity to change this. Like the now-dominant paradigms of web and mobile computing, a local-first future is not a forgone conclusion - but it is possible. What if we tried really hard to make filesystems and composable, small, programs usable for ordinary people? What if we designed software in a way that allowed people to take control of their own data? What if we made a bet on increasing computer literacy, rather than surrendering ourselves to infantilizing users?  ", "parent": "The AI-first operating system of the future.txt", "score": 0.5572843551635742}, {"content": "Thinking about offline first software, and how offline, open source AI models combined with CRDTs might offer the opportunity to create offline-first software that is not only more private than cloud software, but also *better.*", "parent": "NOW-Jan-05-2024.txt", "score": 0.566504955291748}], "I was drawn to the idea of a simple world state - a simple two dimensional array of text. I figured it would be difficult for the LLM to simulate convincing theory of mind (e.g. agents can plot against other agents without the other agents knowing )with just a 2D grid, so I added additional state to simulate the memory and thought process of agents. In practice, this is all very simple as well - it's just an array of text, representing the agent's past thought processes.": [{"content": "I was drawn to the idea of a simple world state - a simple two dimensional array of text. I figured it would be difficult for the LLM to simulate convincing theory of mind (e.g. agents can plot against other agents without the other agents knowing )with just a 2D grid, so I added additional state to simulate the memory and thought process of agents. In practice, this is all very simple as well - it's just an array of text, representing the agent's past thought processes.", "parent": "Gridworld.txt", "score": 0.0}, {"content": "The core game state is just a grid of strings. You can denominate agents like so - <agent>. Agents have their own internal thought processes and planning stage at the end of each turn. ", "parent": "Gridworld.txt", "score": 0.31116665660154963}, {"content": "My motivation for working on this project was to explore the frame of LLMs as simulators. Could you use LLMs to simulate how multiple agents interact with each other in a given scenario?", "parent": "Gridworld.txt", "score": 0.4532905262321635}, {"content": "In practice, I had to add quite a few \"proofreading\" steps and some bespoke logic to spot invalid game states - agents suddenly disappearing from the grid, agents suddenly jumping across the map, agents showing up twice because the world reconciliation step didn't erase the agent's previous position, etc.", "parent": "Gridworld.txt", "score": 0.45705530633246005}, {"content": "The core game loop looks like this: At the end of each turn, extract all agents from the board (by finding cells that contain text that matches <agent>). For each agent, plot what action to take, given the current board state and the agent's past history. Then, for the grid as a whole, consider any environmental affects that might happen (fire spreading, rivers flowing, etc). Finally, given all agent actions and environmental affects, decide the next state of the grid.", "parent": "Gridworld.txt", "score": 0.47076113068022374}, {"content": "[People have researched this topic in the past.](https://arxiv.org/pdf/2304.03442) Usually, however, they've used fairly complicated world simulators and agent loops. Given vast improvements in model quality, is it possible to eschew this programmatic scaffolding in favor of something simpler? This seems to be a general trend with language models - as base models improve, the amount of programmatic \"scaffolding\" you need around them decreases. For example, as context windows have increased, RAG is used less often. You can skip the overhead of spinning up a vector database in favor of just stuffing all your context into the prompt.", "parent": "Gridworld.txt", "score": 0.538019109076378}, {"content": "That makes the answer to the question, \"Can you get rid of scaffolding in favor of just relying on the base model?\" a resounding no. The models really struggle with maintaining object permanence. You need to model this programmatically - even if the context window is large enough to store a world model, the LLM itself hallucinates too often to maintain coherence over multiple turns.", "parent": "Gridworld.txt", "score": 0.5516397441364951}, {"content": "[Gridworld](https://gridworld.nicholaschen.io) is a turn-based, LLM-based, grid-based world simulator. ", "parent": "Gridworld.txt", "score": 0.5903190658019271}, {"content": "The vision is to have a tool that provides a visual interface for creating layouts, and maybe even rigging up basic stateful logic, or data fetching logic. I've more or less nailed down a preferred personal stack for creating projects with React, Express and Postgres, so it shouldn't be terribly difficult to even integrate database logic/fetching logic into such a tool (so long as some flexibility is lost on technology choice).[[code]] [[ideas]] [[tools for thought]] ", "parent": "untitled-9-24-2021.txt", "score": 0.5954838991165161}, {"content": "One fun thing about this project is it made me think a lot about grids. Grids are cool! You can use them in lots of unorthodox ways. I saw [Clavier36](https://clavier36.com/) while working on Gridworld and it made me wonder what a similar interface for composing prompts might look like.  ", "parent": "Gridworld.txt", "score": 0.6105223479046171}], "The core game loop looks like this: At the end of each turn, extract all agents from the board (by finding cells that contain text that matches <agent>). For each agent, plot what action to take, given the current board state and the agent's past history. Then, for the grid as a whole, consider any environmental affects that might happen (fire spreading, rivers flowing, etc). Finally, given all agent actions and environmental affects, decide the next state of the grid.": [{"content": "The core game loop looks like this: At the end of each turn, extract all agents from the board (by finding cells that contain text that matches <agent>). For each agent, plot what action to take, given the current board state and the agent's past history. Then, for the grid as a whole, consider any environmental affects that might happen (fire spreading, rivers flowing, etc). Finally, given all agent actions and environmental affects, decide the next state of the grid.", "parent": "Gridworld.txt", "score": 3.5878431448033155e-07}, {"content": "The core game state is just a grid of strings. You can denominate agents like so - <agent>. Agents have their own internal thought processes and planning stage at the end of each turn. ", "parent": "Gridworld.txt", "score": 0.26637616226121386}, {"content": "In practice, I had to add quite a few \"proofreading\" steps and some bespoke logic to spot invalid game states - agents suddenly disappearing from the grid, agents suddenly jumping across the map, agents showing up twice because the world reconciliation step didn't erase the agent's previous position, etc.", "parent": "Gridworld.txt", "score": 0.41335398475066054}, {"content": "I was drawn to the idea of a simple world state - a simple two dimensional array of text. I figured it would be difficult for the LLM to simulate convincing theory of mind (e.g. agents can plot against other agents without the other agents knowing )with just a 2D grid, so I added additional state to simulate the memory and thought process of agents. In practice, this is all very simple as well - it's just an array of text, representing the agent's past thought processes.", "parent": "Gridworld.txt", "score": 0.4707398489849365}, {"content": "[Gridworld](https://gridworld.nicholaschen.io) is a turn-based, LLM-based, grid-based world simulator. ", "parent": "Gridworld.txt", "score": 0.5470725574322601}, {"content": "My motivation for working on this project was to explore the frame of LLMs as simulators. Could you use LLMs to simulate how multiple agents interact with each other in a given scenario?", "parent": "Gridworld.txt", "score": 0.6420132364059263}, {"content": "One fun thing about this project is it made me think a lot about grids. Grids are cool! You can use them in lots of unorthodox ways. I saw [Clavier36](https://clavier36.com/) while working on Gridworld and it made me wonder what a similar interface for composing prompts might look like.  ", "parent": "Gridworld.txt", "score": 0.6558762461541774}, {"content": "[People have researched this topic in the past.](https://arxiv.org/pdf/2304.03442) Usually, however, they've used fairly complicated world simulators and agent loops. Given vast improvements in model quality, is it possible to eschew this programmatic scaffolding in favor of something simpler? This seems to be a general trend with language models - as base models improve, the amount of programmatic \"scaffolding\" you need around them decreases. For example, as context windows have increased, RAG is used less often. You can skip the overhead of spinning up a vector database in favor of just stuffing all your context into the prompt.", "parent": "Gridworld.txt", "score": 0.6688366195732394}, {"content": "Psychology, ethics, and game theory are diverse fields that all point towards blindness being situationally useful. All fields relate to human action, so maybe it's possible to generalize this on that level. ", "parent": "Strategic blindness.txt", "score": 0.6736409068107605}, {"content": "In game theory, there are mixed strategic games where the Nash equilibrium for all parties is to choose randomly. Here, the only way to blind one's opponent is to blind oneself too. ", "parent": "Strategic blindness.txt", "score": 0.6897165179252625}], "In practice, I had to add quite a few \"proofreading\" steps and some bespoke logic to spot invalid game states - agents suddenly disappearing from the grid, agents suddenly jumping across the map, agents showing up twice because the world reconciliation step didn't erase the agent's previous position, etc.": [{"content": "In practice, I had to add quite a few \"proofreading\" steps and some bespoke logic to spot invalid game states - agents suddenly disappearing from the grid, agents suddenly jumping across the map, agents showing up twice because the world reconciliation step didn't erase the agent's previous position, etc.", "parent": "Gridworld.txt", "score": 3.523841022312624e-07}, {"content": "The core game loop looks like this: At the end of each turn, extract all agents from the board (by finding cells that contain text that matches <agent>). For each agent, plot what action to take, given the current board state and the agent's past history. Then, for the grid as a whole, consider any environmental affects that might happen (fire spreading, rivers flowing, etc). Finally, given all agent actions and environmental affects, decide the next state of the grid.", "parent": "Gridworld.txt", "score": 0.413323195871377}, {"content": "The core game state is just a grid of strings. You can denominate agents like so - <agent>. Agents have their own internal thought processes and planning stage at the end of each turn. ", "parent": "Gridworld.txt", "score": 0.43622851938854856}, {"content": "I was drawn to the idea of a simple world state - a simple two dimensional array of text. I figured it would be difficult for the LLM to simulate convincing theory of mind (e.g. agents can plot against other agents without the other agents knowing )with just a 2D grid, so I added additional state to simulate the memory and thought process of agents. In practice, this is all very simple as well - it's just an array of text, representing the agent's past thought processes.", "parent": "Gridworld.txt", "score": 0.4570672335094753}, {"content": "In high school, I made this [platformer game](https://nichwch.itch.io/machinegods) that I thought was quite easy but my friends found to be incredibly difficult. It turned out that I'd developed an incredible amount of muscle memory while testing the game out. I'm always scared that something similar will happen with the applications that I design. It's worse because I code and design my own projects, and sometimes it's not clear if I designed something because it's intuitive, or because it matches the database schema more cleanly. On the one hand, it feels incredibly elegant to have your design to express the same consistent schema both in its user-facing interface and its inner workings. On the other hand, isn't your job as a designer to shield your users from complexity?", "parent": "Narcissus.txt", "score": 0.5824973150774073}, {"content": "My motivation for working on this project was to explore the frame of LLMs as simulators. Could you use LLMs to simulate how multiple agents interact with each other in a given scenario?", "parent": "Gridworld.txt", "score": 0.5913828492589144}, {"content": "[People have researched this topic in the past.](https://arxiv.org/pdf/2304.03442) Usually, however, they've used fairly complicated world simulators and agent loops. Given vast improvements in model quality, is it possible to eschew this programmatic scaffolding in favor of something simpler? This seems to be a general trend with language models - as base models improve, the amount of programmatic \"scaffolding\" you need around them decreases. For example, as context windows have increased, RAG is used less often. You can skip the overhead of spinning up a vector database in favor of just stuffing all your context into the prompt.", "parent": "Gridworld.txt", "score": 0.6224130188263216}, {"content": "Why did it take so long? Part of it is just a lack of experience. While making exegesis, I changed the database schema countless times, wrote dozens of migrations, accidentally wiped my database once (thank God for RDS backups), and rewrote the backend from scratch 2 months before release. There was also a good amount of feature creep. Whenever I thought I was close to finished, something unexpected would pop up - I started writing this essay 3 months before I actually released exegesis. Whatever the reason, if you count development time on the predecessor to exegesis, I've spent almost a tenth of my life building this. The entire project clocks in at a couple thousand lines of code. It is the largest, most complex, and most difficult thing I have built so far in my life.  [The last time I worked on a project this long, it was the first video game I made back in my senior year of high school.](https://medium.com/@nichwch/machine-gods-devlog-1-166dff474366) Even then, it was really about 6 months of development total, with a huge gap in between because of school, and it was all made with no-code game development tools, because back then the idea of using actual code terrified me. [[exegesis]] [[personal-reflection]] ", "parent": "Reflections on exegesis.txt", "score": 0.6231886148452759}, {"content": "[Gridworld](https://gridworld.nicholaschen.io) is a turn-based, LLM-based, grid-based world simulator. ", "parent": "Gridworld.txt", "score": 0.6270225362149101}, {"content": "That makes the answer to the question, \"Can you get rid of scaffolding in favor of just relying on the base model?\" a resounding no. The models really struggle with maintaining object permanence. You need to model this programmatically - even if the context window is large enough to store a world model, the LLM itself hallucinates too often to maintain coherence over multiple turns.", "parent": "Gridworld.txt", "score": 0.627438931799886}], "That makes the answer to the question, \"Can you get rid of scaffolding in favor of just relying on the base model?\" a resounding no. The models really struggle with maintaining object permanence. You need to model this programmatically - even if the context window is large enough to store a world model, the LLM itself hallucinates too often to maintain coherence over multiple turns.": [{"content": "That makes the answer to the question, \"Can you get rid of scaffolding in favor of just relying on the base model?\" a resounding no. The models really struggle with maintaining object permanence. You need to model this programmatically - even if the context window is large enough to store a world model, the LLM itself hallucinates too often to maintain coherence over multiple turns.", "parent": "Gridworld.txt", "score": 2.220446049250313e-16}, {"content": "[People have researched this topic in the past.](https://arxiv.org/pdf/2304.03442) Usually, however, they've used fairly complicated world simulators and agent loops. Given vast improvements in model quality, is it possible to eschew this programmatic scaffolding in favor of something simpler? This seems to be a general trend with language models - as base models improve, the amount of programmatic \"scaffolding\" you need around them decreases. For example, as context windows have increased, RAG is used less often. You can skip the overhead of spinning up a vector database in favor of just stuffing all your context into the prompt.", "parent": "Gridworld.txt", "score": 0.45828000602994234}, {"content": "I was drawn to the idea of a simple world state - a simple two dimensional array of text. I figured it would be difficult for the LLM to simulate convincing theory of mind (e.g. agents can plot against other agents without the other agents knowing )with just a 2D grid, so I added additional state to simulate the memory and thought process of agents. In practice, this is all very simple as well - it's just an array of text, representing the agent's past thought processes.", "parent": "Gridworld.txt", "score": 0.5516397441364951}, {"content": "My motivation for working on this project was to explore the frame of LLMs as simulators. Could you use LLMs to simulate how multiple agents interact with each other in a given scenario?", "parent": "Gridworld.txt", "score": 0.6074816064690001}, {"content": "In practice, I had to add quite a few \"proofreading\" steps and some bespoke logic to spot invalid game states - agents suddenly disappearing from the grid, agents suddenly jumping across the map, agents showing up twice because the world reconciliation step didn't erase the agent's previous position, etc.", "parent": "Gridworld.txt", "score": 0.6274831500997318}, {"content": "In high school, I made this [platformer game](https://nichwch.itch.io/machinegods) that I thought was quite easy but my friends found to be incredibly difficult. It turned out that I'd developed an incredible amount of muscle memory while testing the game out. I'm always scared that something similar will happen with the applications that I design. It's worse because I code and design my own projects, and sometimes it's not clear if I designed something because it's intuitive, or because it matches the database schema more cleanly. On the one hand, it feels incredibly elegant to have your design to express the same consistent schema both in its user-facing interface and its inner workings. On the other hand, isn't your job as a designer to shield your users from complexity?", "parent": "Narcissus.txt", "score": 0.6697969783585773}, {"content": "[Gridworld](https://gridworld.nicholaschen.io) is a turn-based, LLM-based, grid-based world simulator. ", "parent": "Gridworld.txt", "score": 0.6744359170562196}, {"content": "However, when building Yurt, the static site builder for nomad hypertext, I found myself repeating a lot of logic. I found myself wanting to add features to the indexing engine, like being able to use cloud providers instead of local models (because doing all this processing locally can take ages!). In the future, I might want to use multimodal models, so I can see similarity between images, text, and audio. \n\nFactoring out the semantic search element of my app would have been the correct, unix-ey thing to do, and it would allow me to make these extensions in the future. I plan on doing this soon.  ", "parent": "The making of Nomad Hypertext.txt", "score": 0.6777401566505432}, {"content": "The core game state is just a grid of strings. You can denominate agents like so - <agent>. Agents have their own internal thought processes and planning stage at the end of each turn. ", "parent": "Gridworld.txt", "score": 0.6784135821653134}, {"content": "A safer (and more correct) assumption: *you* serve your tools, not the other way around. This puts a much higher burden on a designer - you are not making something people will use, you are making something people will (consciously or not) adapt themselves to and *serve*. Thinking this way puts you in a much more paranoid state of mind, which I believe is the correct stance to take towards technology. (1)", "parent": "Narcissus.txt", "score": 0.6868257599666268}], "Reflecting on how this went, I'm glad I branched out into another project, but I honestly don't really care about Gridworld all that much. It feels disconnected from everything else I made and I'm not super interested in following up more on it. I think the approach of working on one main project with breaks to work on smaller projects is a good one, but I want those smaller projects to be more related to my main project. I have lots of side project ideas related to tools for thought and music. I thought it'd be cool to do LLM research for its own sake, but I've realized I don't care all that much about the fundamental properties of LLMs - I care more about using them as a tool to build the things I already want to build. There are plenty of possibilities there, for example adding semantic search to Synesthesia to supplement the tagging system (which I honestly do not like at all). As I continue to build side projects in my spare time I want to keep this in mind.": [{"content": "Reflecting on how this went, I'm glad I branched out into another project, but I honestly don't really care about Gridworld all that much. It feels disconnected from everything else I made and I'm not super interested in following up more on it. I think the approach of working on one main project with breaks to work on smaller projects is a good one, but I want those smaller projects to be more related to my main project. I have lots of side project ideas related to tools for thought and music. I thought it'd be cool to do LLM research for its own sake, but I've realized I don't care all that much about the fundamental properties of LLMs - I care more about using them as a tool to build the things I already want to build. There are plenty of possibilities there, for example adding semantic search to Synesthesia to supplement the tagging system (which I honestly do not like at all). As I continue to build side projects in my spare time I want to keep this in mind.", "parent": "Gridworld.txt", "score": 5.276236178297644e-05}, {"content": "I've vacillated on this blog between the idea of working on small projects and working on large projects. I thought I'd try something of a hybrid approach - having a main project, and then working on spinoff projects when I need a break. I spent last week working on such a project.", "parent": "Gridworld.txt", "score": 0.3718251184767467}, {"content": "I want to try a different approach this time. There will be no central organizing idea or principle. Playing the guitar taught me that my creative process works best when I'm free to noodle on the ideas that are immediately interesting to me, not ideas that are part of some preset plan. I have fond memories of sitting on the bus back from my first internship, cracking open my laptop, deciding to try and hack together a first version of YANA. I feel considerably less nostalgic for the late nights I spent during the pandemic trying to \"scale\" my idea, wrestling with pitch decks and AWS dashboards. I had lots of other ideas at the time, but didn't work on them because I felt focusing on exegesis was the correct thing to do. When I first started playing the guitar, I felt guilty learning other songs if I hadn't finished learning a past song. In reality, giving up on songs/concepts I wasn't interested in was incredibly good for my learning in the long run (provided I was still learning new things).", "parent": "Interface Work.txt", "score": 0.4125502109527588}, {"content": "I have not had as much time to work on programming side projects. In general, I've been spending more spare time on music rather than programming. There's nothing intrinsically wrong with that, but I feel like it's less a reflection of what I want than it is a reflection of my environment. \n\nI don't actually find music to be more fulfilling than programming. I got into playing the guitar mostly by accident and to be honest I am much better at the guitar than I am at programming, but playing the guitar was never my dream growing up. There are software ideas that I am excited about and obsessed with. I don't really feel the same way about music.", "parent": "NOW PAGE.txt", "score": 0.4169580936431885}, {"content": "The good news is I've found a method of working on side projects that does work for me: working on one side project at a time, with the intention of getting real users. This is a way of working I previously tried explicitly to steer away from - I've written previously on my blog that I wanted to work on lots of small projects instead of obsessively on one big project. ", "parent": "An Update.txt", "score": 0.42926663160324097}, {"content": "One fun thing about this project is it made me think a lot about grids. Grids are cool! You can use them in lots of unorthodox ways. I saw [Clavier36](https://clavier36.com/) while working on Gridworld and it made me wonder what a similar interface for composing prompts might look like.  ", "parent": "Gridworld.txt", "score": 0.4366728774965628}, {"content": "My goal in life right now is to focus more on programming, while keeping music as a hobby. I want to improve at both, and someday I'd like to unite these two interests - not in some surface level way like getting really into digital signal processing or generative music, but by making the process of writing software more like the process of making music (intuitive, embodied, modular, composable).", "parent": "NOW PAGE.txt", "score": 0.440967857837677}, {"content": "The previous method of working I sketched out in this blog (working on small projects, writing about them in public) is not working for me. It was working for me for a while, mostly while I was building at the Recurse center, but it's not anymore, and it's because I just don't feel motivated to work on lots of small projects that no one uses. ", "parent": "An Update.txt", "score": 0.44100838899612427}, {"content": "I don't care if my work gets noticed, or if it's any good, or if it leads to anything at all. I don't know if I have any talent for interface research, but it seems like I might - my sophomore year of college, I designed a notetaking tool called YANA with a novel interface where you could select text and then add tags to it. The response to it was very positive, which encouraged me to try and build a startup out of it, which unfortunately led to me becoming monomaniacally obsessed with that idea at the expense of trying to explore any other ideas (an obsession I only shed once I made Nomad Hypertext, which I could call a \"finished\" product). ", "parent": "Interface Work.txt", "score": 0.44985997676849365}, {"content": "I've found writing down tasks and decomposing them into smaller ones helps. Right now, I do this in [[exegesis]], which honestly feels somewhat suboptimal. I also have another side project called [https://focusmachine.app/](https://focusmachine.app/) to remind me of what I'm currently supposed to be focusing - it's really stupid, it just asks you what you want to work on and then spams you with a reminder to focus on that at user-inputted interval. [[focus]] [[focus-machine]] [[ideas]] [[exegesis]] ", "parent": "untitled-9-24-2021.txt", "score": 0.4541425108909607}], "One fun thing about this project is it made me think a lot about grids. Grids are cool! You can use them in lots of unorthodox ways. I saw [Clavier36](https://clavier36.com/) while working on Gridworld and it made me wonder what a similar interface for composing prompts might look like.  ": [{"content": "One fun thing about this project is it made me think a lot about grids. Grids are cool! You can use them in lots of unorthodox ways. I saw [Clavier36](https://clavier36.com/) while working on Gridworld and it made me wonder what a similar interface for composing prompts might look like.  ", "parent": "Gridworld.txt", "score": -2.220446049250313e-16}, {"content": "Reflecting on how this went, I'm glad I branched out into another project, but I honestly don't really care about Gridworld all that much. It feels disconnected from everything else I made and I'm not super interested in following up more on it. I think the approach of working on one main project with breaks to work on smaller projects is a good one, but I want those smaller projects to be more related to my main project. I have lots of side project ideas related to tools for thought and music. I thought it'd be cool to do LLM research for its own sake, but I've realized I don't care all that much about the fundamental properties of LLMs - I care more about using them as a tool to build the things I already want to build. There are plenty of possibilities there, for example adding semantic search to Synesthesia to supplement the tagging system (which I honestly do not like at all). As I continue to build side projects in my spare time I want to keep this in mind.", "parent": "Gridworld.txt", "score": 0.4362914598478189}, {"content": "[Gridworld](https://gridworld.nicholaschen.io) is a turn-based, LLM-based, grid-based world simulator. ", "parent": "Gridworld.txt", "score": 0.45100574691408246}, {"content": "I'm not really sure how to square this. One idea I've been obsessed with is how I can make the process of writing software more like the process of making music. ", "parent": "NOW PAGE.txt", "score": 0.48818641901016235}, {"content": "In fact, in the middle of an essay, I should be able to invent a UI component just to illustrate a point.\n\nEarly internet vibes.", "parent": "Fragments.txt", "score": 0.5035684704780579}, {"content": "As I looked further into these tools, I found that some had taken to calling them [Second Brains](https://fortelabs.co/blog/basboverview/). I thought this was incredibly exciting. The term sounds cyberpunk; building a \"second brain\" sounds way cooler than building a \"note taking app.\" At the same time, something about it unsettled me. ", "parent": "Second Brains.txt", "score": 0.5135635137557983}, {"content": "I bring this up because it would be nice if there were a way to \"compose\" UI features the same way you can compose command line features. Imagine if I had been able to add a stealth button to my app without editing my app, but by building a new app that I then composed my app with. There are lots of other UI elements I'd like to add to my app - maybe a button that pushes all my notes up to Github, for example. ", "parent": "Interface Work: Stealth Button.txt", "score": 0.5150184035301208}, {"content": "I've found writing down tasks and decomposing them into smaller ones helps. Right now, I do this in [[exegesis]], which honestly feels somewhat suboptimal. I also have another side project called [https://focusmachine.app/](https://focusmachine.app/) to remind me of what I'm currently supposed to be focusing - it's really stupid, it just asks you what you want to work on and then spams you with a reminder to focus on that at user-inputted interval. [[focus]] [[focus-machine]] [[ideas]] [[exegesis]] ", "parent": "untitled-9-24-2021.txt", "score": 0.5235668420791626}, {"content": "I rewrote the indexing software for this blog in Python. The general philosophy of keeping things as modular as possible, storing content in interoperable, plain formats whenever possible, has been paying off. I'm realizing slowly how many other possibilities are opened up by keeping content in plaintext/markdown - I can write a weekend project mapping my blog posts by topic and time, I can create a word cloud visualization of my blog, I can build a game of pong where the blocks are paragraphs of my blogposts, all without touching any existing code. ", "parent": "NOW PAGE.txt", "score": 0.5268666744232178}, {"content": "It was nice building a new feature for an app I haven't touched in a while. Still, it got me thinking about extensibility and composability. ", "parent": "Interface Work: Stealth Button.txt", "score": 0.5304293632507324}], "  ": [{"content": "  ", "parent": "Gridworld.txt", "score": 0.0}, {"content": "  ", "parent": "Narcissus.txt", "score": 9.618186328497202e-07}, {"content": "  ", "parent": "Narcissus.txt", "score": 1.0316966061463262e-06}, {"content": "  ", "parent": "The making of Nomad Hypertext.txt", "score": 1.9669532775878906e-06}, {"content": " ", "parent": "Plaintext is your best friend.txt", "score": 0.08612757921218872}, {"content": " ", "parent": "NOW PAGE.txt", "score": 0.08616328239440918}, {"content": " ", "parent": "Interface Journal: Summary Tool.txt", "score": 0.08616328239440918}, {"content": " ", "parent": "Interface Journal: Summary Tool.txt", "score": 0.08616328239440918}, {"content": " ", "parent": "Narcissus.txt", "score": 0.08616339216183688}, {"content": " ", "parent": "untitled-10-11-2021.txt", "score": 0.08616805076599121}]}